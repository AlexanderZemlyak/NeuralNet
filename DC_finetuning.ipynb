{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4c9b026ad524bd7ad8e193a69067460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a428317e8fe84d0fae3446007e9f8673",
              "IPY_MODEL_4e6c6ea332d544a9bb5b09b63465e4cf",
              "IPY_MODEL_937d430ba31247faabea62e66c7c9ac8"
            ],
            "layout": "IPY_MODEL_d93c9acb08db41b091030d9916afb45d"
          }
        },
        "a428317e8fe84d0fae3446007e9f8673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f86958cc9684d748ed7734d9244361f",
            "placeholder": "​",
            "style": "IPY_MODEL_e4602b553824409c9fc73c3e24b764f1",
            "value": "config.json: 100%"
          }
        },
        "4e6c6ea332d544a9bb5b09b63465e4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7229015f3bd344508928e60be7e919bc",
            "max": 631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3322076c6ae0450b9e10c54ac7e6756e",
            "value": 631
          }
        },
        "937d430ba31247faabea62e66c7c9ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318df084a32d452e9d30ed2066192607",
            "placeholder": "​",
            "style": "IPY_MODEL_18f5ced510754eb6b44a1b39b4d5b378",
            "value": " 631/631 [00:00&lt;00:00, 19.5kB/s]"
          }
        },
        "d93c9acb08db41b091030d9916afb45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f86958cc9684d748ed7734d9244361f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4602b553824409c9fc73c3e24b764f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7229015f3bd344508928e60be7e919bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3322076c6ae0450b9e10c54ac7e6756e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "318df084a32d452e9d30ed2066192607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f5ced510754eb6b44a1b39b4d5b378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d421c6d4dfa4fd4b22ea24167b3bcc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a2cad17aa6e4124819421093246d1d9",
              "IPY_MODEL_e6ffc29d9f3043dd924bbd1f2f116d5e",
              "IPY_MODEL_0b36e1a7926d4c8fb46f7cb8719c48b2"
            ],
            "layout": "IPY_MODEL_017dc317a0c849aaa5e88e7dfa0b5c3e"
          }
        },
        "1a2cad17aa6e4124819421093246d1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233da90970e046c88278a6c5ada28e96",
            "placeholder": "​",
            "style": "IPY_MODEL_54e1b9c0432c4e93b45f480d6f9149f1",
            "value": "model.safetensors: 100%"
          }
        },
        "e6ffc29d9f3043dd924bbd1f2f116d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36bd5d9b94964975b407781443cecddc",
            "max": 2692969128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1734d752f9440a18a3846dd199c0763",
            "value": 2692969128
          }
        },
        "0b36e1a7926d4c8fb46f7cb8719c48b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b78a7930a54f7eb644f590db26ba70",
            "placeholder": "​",
            "style": "IPY_MODEL_53964da667fa460dbfa408c55dbf0c29",
            "value": " 2.69G/2.69G [01:36&lt;00:00, 47.1MB/s]"
          }
        },
        "017dc317a0c849aaa5e88e7dfa0b5c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233da90970e046c88278a6c5ada28e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e1b9c0432c4e93b45f480d6f9149f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36bd5d9b94964975b407781443cecddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1734d752f9440a18a3846dd199c0763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48b78a7930a54f7eb644f590db26ba70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53964da667fa460dbfa408c55dbf0c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55678bd3780743c49d50711d7c2676d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31c485abb47043409863fa010ee065e5",
              "IPY_MODEL_bcdf23462d8b4310b1050b11ed1e24d2",
              "IPY_MODEL_52c464a5a7484a5bb964d4ad959b026b"
            ],
            "layout": "IPY_MODEL_af87195123ca44b3aeed63760a476c7b"
          }
        },
        "31c485abb47043409863fa010ee065e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f91048b41840d3aaee700ee32c929b",
            "placeholder": "​",
            "style": "IPY_MODEL_94e29332ae4e4295b1efafd7df25e15e",
            "value": "generation_config.json: 100%"
          }
        },
        "bcdf23462d8b4310b1050b11ed1e24d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b98e596defc412290cb00a6e43645ce",
            "max": 119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4eaac59b11b74a919284bae1530d0d56",
            "value": 119
          }
        },
        "52c464a5a7484a5bb964d4ad959b026b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_640d878e43544ad1b699fc43010c7023",
            "placeholder": "​",
            "style": "IPY_MODEL_406dcccc967e4452a2624ebdad146a21",
            "value": " 119/119 [00:00&lt;00:00, 13.2kB/s]"
          }
        },
        "af87195123ca44b3aeed63760a476c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f91048b41840d3aaee700ee32c929b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e29332ae4e4295b1efafd7df25e15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b98e596defc412290cb00a6e43645ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eaac59b11b74a919284bae1530d0d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "640d878e43544ad1b699fc43010c7023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "406dcccc967e4452a2624ebdad146a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b76e103c954d22b7bf21e6ea4c7592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4797988ab317430eb39a8d55edae4fbb",
              "IPY_MODEL_986e76ae04dc456e8c04f39d7f49431e",
              "IPY_MODEL_9147f0b63b734b078c7c5fbb6ebba034"
            ],
            "layout": "IPY_MODEL_847fc16a99284813ad11f9d479acac50"
          }
        },
        "4797988ab317430eb39a8d55edae4fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6289b189e7b44febe4b5da9353195fe",
            "placeholder": "​",
            "style": "IPY_MODEL_1fc0914f51a64e7bbea9fa7dfed28e8e",
            "value": "tokenizer_config.json: "
          }
        },
        "986e76ae04dc456e8c04f39d7f49431e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef3a940a1cd4db9bcdb0027cf38228a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1966e6ba6ce4906bc9596d5c4a6be83",
            "value": 1
          }
        },
        "9147f0b63b734b078c7c5fbb6ebba034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2a3ca60b03478da6fe49a95211dc9f",
            "placeholder": "​",
            "style": "IPY_MODEL_1318d0c28ccf4bb9a69746f284848cf5",
            "value": " 1.87k/? [00:00&lt;00:00, 39.4kB/s]"
          }
        },
        "847fc16a99284813ad11f9d479acac50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6289b189e7b44febe4b5da9353195fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc0914f51a64e7bbea9fa7dfed28e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ef3a940a1cd4db9bcdb0027cf38228a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b1966e6ba6ce4906bc9596d5c4a6be83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb2a3ca60b03478da6fe49a95211dc9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1318d0c28ccf4bb9a69746f284848cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3953181544504c4a8b149fb26cb4f912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05542fcb720d4d86b16c6e4651ef584a",
              "IPY_MODEL_74c65882e0c94c6087a70f99afc994e0",
              "IPY_MODEL_ac01751420e747c09a0c7e0ad9daadb1"
            ],
            "layout": "IPY_MODEL_4cc1c5bbfbe4473492e2918d81dafdb3"
          }
        },
        "05542fcb720d4d86b16c6e4651ef584a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6432eb622b49aa94b0616be6d28ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_4516cf573e5448f99867a66d77bc1526",
            "value": "tokenizer.json: "
          }
        },
        "74c65882e0c94c6087a70f99afc994e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8db923f6f9914c3eb4823e0e78d41a5e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16381f8e44144c88b55b81722c560db8",
            "value": 1
          }
        },
        "ac01751420e747c09a0c7e0ad9daadb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca10175ced547a29581efee2757cba0",
            "placeholder": "​",
            "style": "IPY_MODEL_0d849037614d435f830c13141060f466",
            "value": " 1.37M/? [00:00&lt;00:00, 18.4MB/s]"
          }
        },
        "4cc1c5bbfbe4473492e2918d81dafdb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6432eb622b49aa94b0616be6d28ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4516cf573e5448f99867a66d77bc1526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8db923f6f9914c3eb4823e0e78d41a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "16381f8e44144c88b55b81722c560db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dca10175ced547a29581efee2757cba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d849037614d435f830c13141060f466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d90424c3e5461cb65b1714e2bc7d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c513ddd7a68b45d2a06d4d4e4212db50",
              "IPY_MODEL_32b0807409334b08a3eca29efade2df2",
              "IPY_MODEL_54eef423d10b47dfa7cc9aec0e313ac6"
            ],
            "layout": "IPY_MODEL_59018488727044ad8c96f6509ab7b3b6"
          }
        },
        "c513ddd7a68b45d2a06d4d4e4212db50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_461a3cebb27e46a88a0f5f41660c46f4",
            "placeholder": "​",
            "style": "IPY_MODEL_832a25e9f7064d8bb217cd27528b859f",
            "value": "config.json: 100%"
          }
        },
        "32b0807409334b08a3eca29efade2df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c63b9e8f5ed44bba0bdb4e5fa617e32",
            "max": 631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e84fe182cbc54dffb86371fb07a93634",
            "value": 631
          }
        },
        "54eef423d10b47dfa7cc9aec0e313ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b1a5a3254b454ba055c60de5f59e03",
            "placeholder": "​",
            "style": "IPY_MODEL_61a1e5930b9c462ba252e4f7d7580c4f",
            "value": " 631/631 [00:00&lt;00:00, 56.8kB/s]"
          }
        },
        "59018488727044ad8c96f6509ab7b3b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "461a3cebb27e46a88a0f5f41660c46f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832a25e9f7064d8bb217cd27528b859f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c63b9e8f5ed44bba0bdb4e5fa617e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84fe182cbc54dffb86371fb07a93634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1b1a5a3254b454ba055c60de5f59e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a1e5930b9c462ba252e4f7d7580c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9824a99791204043844b7619ad156c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd667787b4da4fbb92c96e6cc6b4884c",
              "IPY_MODEL_1b80645936c64a9c87491b92e243d9a6",
              "IPY_MODEL_8699f004ee08457c91c447ec397e3455"
            ],
            "layout": "IPY_MODEL_e3e24c048f634e158588c3247f612acc"
          }
        },
        "dd667787b4da4fbb92c96e6cc6b4884c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb90f5bc7334ae482660460d018c028",
            "placeholder": "​",
            "style": "IPY_MODEL_d9ad450120744df6bdb6bf47211abbcc",
            "value": "model.safetensors: 100%"
          }
        },
        "1b80645936c64a9c87491b92e243d9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e506d2c39a45439db0a9dca5e3758b",
            "max": 2692969128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9857321744246aabc50a09579365889",
            "value": 2692969128
          }
        },
        "8699f004ee08457c91c447ec397e3455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9759c0da919a4ea6901eccff26ef7e30",
            "placeholder": "​",
            "style": "IPY_MODEL_2bfb05e3d9ea4b75ae161d3656b04d33",
            "value": " 2.69G/2.69G [01:07&lt;00:00, 92.4MB/s]"
          }
        },
        "e3e24c048f634e158588c3247f612acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bb90f5bc7334ae482660460d018c028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ad450120744df6bdb6bf47211abbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e506d2c39a45439db0a9dca5e3758b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9857321744246aabc50a09579365889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9759c0da919a4ea6901eccff26ef7e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfb05e3d9ea4b75ae161d3656b04d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1c913879ae542fc85aac1bbfac7f137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd43b31e6f424f8a9d87d3613342a840",
              "IPY_MODEL_1ef0e02b424949539da45389d33eb401",
              "IPY_MODEL_b76b4617e4e34e98b25685d34aefdb07"
            ],
            "layout": "IPY_MODEL_b9567fa3d418484d869d1a4884db441e"
          }
        },
        "bd43b31e6f424f8a9d87d3613342a840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c8202464714409a4eca21a1f91f270",
            "placeholder": "​",
            "style": "IPY_MODEL_486d737529e04a3793e4abff27b0b007",
            "value": "generation_config.json: 100%"
          }
        },
        "1ef0e02b424949539da45389d33eb401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75553468954b4fb6806435a40ddd8c21",
            "max": 119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d22593dfa5054be58f6509be912dca6f",
            "value": 119
          }
        },
        "b76b4617e4e34e98b25685d34aefdb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cceea1bc25c4acbb201a2de59e63fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_7c5f6eaa708846da94e5514d3d2f9be5",
            "value": " 119/119 [00:00&lt;00:00, 14.4kB/s]"
          }
        },
        "b9567fa3d418484d869d1a4884db441e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c8202464714409a4eca21a1f91f270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486d737529e04a3793e4abff27b0b007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75553468954b4fb6806435a40ddd8c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22593dfa5054be58f6509be912dca6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cceea1bc25c4acbb201a2de59e63fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5f6eaa708846da94e5514d3d2f9be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7072889bffbc440ca35e1f6806f14c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_361a3632c3d342acb1e81a13fb32fbe2",
              "IPY_MODEL_29bcbb653eae4798bb8948cc318cc08a",
              "IPY_MODEL_49f9dd11dc4b4816b9627e7029f41475"
            ],
            "layout": "IPY_MODEL_3f5dec2c4b8c497e9d11d919bfa3973b"
          }
        },
        "361a3632c3d342acb1e81a13fb32fbe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd6a0152e584c9b831305b5b7e6a997",
            "placeholder": "​",
            "style": "IPY_MODEL_dadb486eee0e45fcbf652729d5a68cc6",
            "value": "tokenizer_config.json: "
          }
        },
        "29bcbb653eae4798bb8948cc318cc08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33c0b655f3546dfa62a89a5843b9075",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d2b4bcc8da44c9a87f487f2bfe33633",
            "value": 1
          }
        },
        "49f9dd11dc4b4816b9627e7029f41475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6d21324ab84e3183319cdefa932448",
            "placeholder": "​",
            "style": "IPY_MODEL_2cbd8c145dec4e0ea5e1637e6ff76283",
            "value": " 1.87k/? [00:00&lt;00:00, 187kB/s]"
          }
        },
        "3f5dec2c4b8c497e9d11d919bfa3973b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd6a0152e584c9b831305b5b7e6a997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dadb486eee0e45fcbf652729d5a68cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e33c0b655f3546dfa62a89a5843b9075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3d2b4bcc8da44c9a87f487f2bfe33633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb6d21324ab84e3183319cdefa932448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbd8c145dec4e0ea5e1637e6ff76283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b919fbd39384377b9c2f67b0ae5f0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d784aebf17346a1aeb02bc504661335",
              "IPY_MODEL_467e117d870f4a2bbe69de1a85d45785",
              "IPY_MODEL_fd744c53423b44da9c2872325db14ea3"
            ],
            "layout": "IPY_MODEL_083815f024174e7caa6c941fe3632ffc"
          }
        },
        "9d784aebf17346a1aeb02bc504661335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5947388f23a14aab9f59b00f8280ae50",
            "placeholder": "​",
            "style": "IPY_MODEL_d370ec969e474e8487e1035390d723b5",
            "value": "tokenizer.json: "
          }
        },
        "467e117d870f4a2bbe69de1a85d45785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e10de4c45b4f435a94249e0ae03f4202",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f56bb5113c3e4fa89b79ae81862fa67d",
            "value": 1
          }
        },
        "fd744c53423b44da9c2872325db14ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45edd8d0c597408b97fa28461493dfa7",
            "placeholder": "​",
            "style": "IPY_MODEL_a4ec99ef807144a6ae1265eb372e5247",
            "value": " 1.37M/? [00:00&lt;00:00, 35.1MB/s]"
          }
        },
        "083815f024174e7caa6c941fe3632ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5947388f23a14aab9f59b00f8280ae50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d370ec969e474e8487e1035390d723b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e10de4c45b4f435a94249e0ae03f4202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f56bb5113c3e4fa89b79ae81862fa67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45edd8d0c597408b97fa28461493dfa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ec99ef807144a6ae1265eb372e5247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "1E_eBdtkjicK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Подключаем Google Drive для сохранения результатов\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoCcOljd8HV1",
        "outputId": "5baf3d01-b233-4740-af9a-0341c1f0a96a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, prompt):\n",
        "    # Форматируем как при обучении\n",
        "    formatted_prompt = f'''\n",
        "You are a PascalABC.NET coding assistant. Follow these rules:\n",
        "1. Write only PascalABC.NET code\n",
        "2. Provide complete programs when possible\n",
        "3. Use modern PascalABC.NET features\n",
        "\n",
        "### Instruction:\n",
        "{prompt}\n",
        "### Response:\n",
        "'''\n",
        "\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1024,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "def test_model_raw(prompt):\n",
        "  formatted_prompt = f'''\n",
        "    ### Instruction:\n",
        "    {prompt}\n",
        "    ### Response:\n",
        "    '''\n",
        "\n",
        "  inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(model2.device)\n",
        "\n",
        "  print(f\"Inputs device: {inputs['input_ids'].device}\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model2.generate(\n",
        "          **inputs,\n",
        "          max_new_tokens=1024,\n",
        "          temperature=0.7,\n",
        "          do_sample=True,\n",
        "          pad_token_id=tokenizer.eos_token_id\n",
        "      )\n",
        "\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  return response"
      ],
      "metadata": {
        "id": "1iCT5Uqx9NsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O54U_pzuj8Q",
        "outputId": "b9e3509c-3041-492a-d193-ff752594f171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here is a simple implementation of the Quick Sort algorithm in Python:\n",
            "\n",
            "```python\n",
            "def quick_sort(arr):\n",
            "    if len(arr) <= 1:\n",
            "        return arr\n",
            "    pivot = arr[len(arr) // 2]\n",
            "    left = [x for x in arr if x < pivot]\n",
            "    middle = [x for x in arr if x == pivot]\n",
            "    right = [x for x in arr if x > pivot]\n",
            "    return quick_sort(left) + middle + quick_sort(right)\n",
            "\n",
            "# Test the function\n",
            "print(quick_sort([3,6,8,10,1,2,1]))\n",
            "# Output: [1, 1, 2, 3, 6, 8, 10]\n",
            "```\n",
            "\n",
            "This algorithm works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted.\n",
            "\n",
            "The pivot selection is done in a way that it divides the array into two halves, one with elements less than the pivot and one with elements greater than the pivot. This is done to ensure that the pivot is in its final sorted position.\n",
            "\n",
            "The time complexity of Quick Sort is O(n log n) in all cases (worst, average, and best) as it needs to do a constant amount of work for each recursive call.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\", trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()\n",
        "messages=[\n",
        "    { 'role': 'user', 'content': \"write quick sort algorithm.\"}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model structure:\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSDFY0GdEIPK",
        "outputId": "8f5e1279-3009-4444-96ff-060e8ef365df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure:\n",
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(32256, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
            "          (act_fn): SiLUActivation()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MqCuF4LSy6r",
        "outputId": "32647890-2066-4867-f875-1bdf3ac5a8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines) (25.4.0)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of transformer layers: {len(model.model.layers)}\")\n",
        "\n",
        "for i, layer in enumerate(model.model.layers):\n",
        "    print(f\"\\n--- Layer {i} ---\")\n",
        "    for name, param in layer.named_parameters():\n",
        "        print(f\"  {name}: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vV891POiKVcu",
        "outputId": "36606c98-4b6a-4f88-ced7-0f7a57dd0a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of transformer layers: 24\n",
            "\n",
            "--- Layer 0 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 1 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 2 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 3 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 4 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 5 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 6 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 7 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 8 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 9 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 10 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 11 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 12 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 13 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 14 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 15 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 16 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 17 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 18 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 19 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 20 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 21 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 22 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n",
            "\n",
            "--- Layer 23 ---\n",
            "  self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
            "  self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
            "  mlp.gate_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.up_proj.weight: torch.Size([5504, 2048])\n",
            "  mlp.down_proj.weight: torch.Size([2048, 5504])\n",
            "  input_layernorm.weight: torch.Size([2048])\n",
            "  post_attention_layernorm.weight: torch.Size([2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    { 'role': 'user', 'content': \"write a Fibonacci numbers printing function in Pascal using modern Pascal style\"}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q9jFcjExCkV",
        "outputId": "71b6126d-60fd-4914-bb19-7969b498836d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a simple implementation of a Fibonacci numbers printing function in Pascal using the modern style:\n",
            "\n",
            "```pascal\n",
            "program Fibonacci;\n",
            "\n",
            "function FibonacciNumbers(n: integer): string;\n",
            "var\n",
            "  a, b, c: integer;\n",
            "begin\n",
            "  if n <= 0 then\n",
            "    result := ''\n",
            "  else if n = 1 then\n",
            "    result := '0'\n",
            "  else if n = 2 then\n",
            "    result := '0, 1'\n",
            "  else\n",
            "  begin\n",
            "    a := 0;\n",
            "    b := 1;\n",
            "    c := 0;\n",
            "    result := '0, 1';\n",
            "    while c < n - 2 do\n",
            "    begin\n",
            "      c := a + b;\n",
            "      a := b;\n",
            "      b := c;\n",
            "      result := result + ', ' + IntToStr(c);\n",
            "    end;\n",
            "  end;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  writeln(FibonacciNumbers(10));\n",
            "end.\n",
            "```\n",
            "\n",
            "This program defines a function `FibonacciNumbers` that generates the first `n` Fibonacci numbers. It starts with the first two Fibonacci numbers (0 and 1) and then continuously adds the last two numbers to generate the next Fibonacci number. The function returns a string of comma-separated Fibonacci numbers.\n",
            "\n",
            "The `begin` statement at the end of the program calls `FibonacciNumbers` with `n` set to 10, and then writes the result to the console.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    { 'role': 'user', 'content': \"напиши на Паскале функцию быстрой сортировки. Все переменные называй с большой буквы.\"}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coFtuiTsKqON",
        "outputId": "b55c5dea-8525-4209-c2a0-5c68aa556221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В Паскале нет встроенной функции для быстрой сортировки, но есть встроенные функции для сортировки списка. Вот примеры:\n",
            "\n",
            "1. Выбор сортировки:\n",
            "\n",
            "```pascal\n",
            "procedure SelectionSort(var A: array of Integer; L, R: Integer);\n",
            "var\n",
            "  i, j, max_i, temp: Integer;\n",
            "begin\n",
            "  for i := L to R - 1 do\n",
            "  begin\n",
            "    max_i := i;\n",
            "    for j := i + 1 to R do\n",
            "      if A[j] > A[max_i] then\n",
            "        max_i := j;\n",
            "    temp := A[i];\n",
            "    A[i] := A[max_i];\n",
            "    A[max_i] := temp;\n",
            "  end;\n",
            "end;\n",
            "```\n",
            "\n",
            "2. Вставка сортировки:\n",
            "\n",
            "```pascal\n",
            "procedure InsertionSort(var A: array of Integer; L, R: Integer);\n",
            "var\n",
            "  i, j, key: Integer;\n",
            "begin\n",
            "  for i := L + 1 to R do\n",
            "  begin\n",
            "    key := A[i];\n",
            "    j := i - 1;\n",
            "    while (j >= L) and (A[j] > key) do\n",
            "    begin\n",
            "      A[j + 1] := A[j];\n",
            "      j := j - 1;\n",
            "    end;\n",
            "    A[j + 1] := key;\n",
            "  end;\n",
            "end;\n",
            "```\n",
            "\n",
            "3. Шелла сортировки:\n",
            "\n",
            "```pascal\n",
            "procedure ShellSort(var A: array of Integer; L, R: Integer);\n",
            "var\n",
            "  gap, i, j, temp: Integer;\n",
            "begin\n",
            "  gap := R div 2;\n",
            "  while gap > 0 do\n",
            "  begin\n",
            "    for i := gap to R do\n",
            "    begin\n",
            "      temp := A[i];\n",
            "      j := i;\n",
            "      while (j >= gap) and (A[j - gap] > temp) do\n",
            "      begin\n",
            "        A[j] := A[j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    { 'role': 'user', 'content': \"Write Hanoi Towers algorithm in python.\"}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=1024, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CunUFd8PkV-1",
        "outputId": "ed172b08-9951-4961-b2df-53697d6848a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Hanoi Towers problem is a classic problem in computer science, which is a mathematical puzzle that can be solved using recursion. The problem consists of three rods and a number of disks of different sizes which can slide onto any rod. The puzzle starts with the disks in a neat stack in ascending order of size on one rod, the smallest at the top, thus making a conical shape.\n",
            "\n",
            "The objective of the puzzle is to move the entire stack to another rod, obeying the following simple rules:\n",
            "\n",
            "1. Only one disk can be moved at a time.\n",
            "2. Each move consists of taking the upper disk from one of the stacks and placing it on top of another stack or on an empty rod.\n",
            "3. No disk may be placed on top of a smaller disk.\n",
            "\n",
            "Here is a Python implementation of the Hanoi Towers algorithm:\n",
            "\n",
            "```python\n",
            "def hanoi(n, source, target, auxiliary):\n",
            "    if n > 0:\n",
            "        # Move n - 1 disks from source to auxiliary, so they are out of the way\n",
            "        hanoi(n - 1, source, auxiliary, target)\n",
            "\n",
            "        # Move the nth disk from source to target\n",
            "        print('Move disk', n, 'from rod', source, 'to rod', target)\n",
            "\n",
            "        # Move the n - 1 disks that we left on auxiliary to target\n",
            "        hanoi(n - 1, auxiliary, target, source)\n",
            "\n",
            "# Test the function\n",
            "hanoi(3, 'A', 'C', 'B')\n",
            "```\n",
            "\n",
            "In this code, `hanoi` is a recursive function that solves the Hanoi Towers problem. It takes four arguments: the number of disks `n`, the name of the source rod, the name of the target rod, and the name of the auxiliary rod.\n",
            "\n",
            "The function first recursively solves the problem for `n - 1` disks, then it moves the `n`th disk from the source to the target, and finally it recursively solves the problem for the `n - 1` disks that we left on the auxiliary rod.\n",
            "\n",
            "The `print` statement inside the function is used to print the moves that are made to solve the problem.\n",
            "\n",
            "The test call to `hanoi(3, 'A', 'C', 'B')` will print the following moves:\n",
            "\n",
            "```\n",
            "Move disk 1 from rod A to rod C\n",
            "Move disk 2 from rod A to rod B\n",
            "Move disk 1 from rod C to rod B\n",
            "Move disk 3 from rod A to rod C\n",
            "Move disk 1 from rod B to rod C\n",
            "Move disk 2 from rod B to rod A\n",
            "Move disk 1 from rod C to rod A\n",
            "Move disk 3 from rod C to rod B\n",
            "Move disk 1 from rod A to rod B\n",
            "Move disk 2 from rod A to rod C\n",
            "Move disk 1 from rod B to rod C\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    { 'role': 'user', 'content': \"Write an algorithm which solves n qweens problem.\"}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=1024, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t5TXqw4BBUz",
        "outputId": "87d68d1c-813c-43fb-fb75-b025670da770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The n-Queens problem is a classic problem in computer science, which asks how to place n queens on an n×n chessboard so that no two queens threaten each other.\n",
            "\n",
            "Here is a simple algorithm to solve the n-Queens problem:\n",
            "\n",
            "1. Initialize a 2D array of size n x n, where each cell represents a row.\n",
            "\n",
            "2. For each row, place a queen in each column.\n",
            "\n",
            "3. Check for any two queens in the same row. If a queen is found, return false.\n",
            "\n",
            "4. Check for any two queens in the same column. If a queen is found, return false.\n",
            "\n",
            "5. Check for any two queens in the same diagonal. If a queen is found, return false.\n",
            "\n",
            "6. If no conflict is found, return true.\n",
            "\n",
            "Here is a Python implementation of the above algorithm:\n",
            "\n",
            "```python\n",
            "def solve_n_queens(n):\n",
            "    def is_attack(i, j):\n",
            "        # Check for any queen in the same row\n",
            "        for k in range(0, n):\n",
            "            if board[i][k] == 1:\n",
            "                return True\n",
            "\n",
            "        # Check for any queen in the same column\n",
            "        for k in range(0, n):\n",
            "            if board[k][j] == 1:\n",
            "                return True\n",
            "\n",
            "        # Check for any queen in the same diagonal\n",
            "        for k in range(0, n):\n",
            "            for l in range(0, n):\n",
            "                if (k + l == i + j) or (k - l == i - j):\n",
            "                    if board[k][l] == 1:\n",
            "                        return True\n",
            "\n",
            "        return False\n",
            "\n",
            "    def solve_n_queens_util(n, i):\n",
            "        # base case\n",
            "        if i == n:\n",
            "            return True\n",
            "\n",
            "        for j in range(0, n):\n",
            "            if not is_attack(i, j):\n",
            "                # place queen at board[i][j]\n",
            "                board[i][j] = 1\n",
            "\n",
            "                # recur to place rest of the queens\n",
            "                if solve_n_queens_util(n, i + 1) == True:\n",
            "                    return True\n",
            "\n",
            "                # If placing queen in board[i][j] doesn't lead to a solution, then\n",
            "                # remove queen from board[i][j]\n",
            "                board[i][j] = 0\n",
            "\n",
            "        return False\n",
            "\n",
            "    board = [[0]*n for _ in range(n)]\n",
            "\n",
            "    if solve_n_queens_util(n, 0) == False:\n",
            "        print(\"Solution does not exist\")\n",
            "        return False\n",
            "\n",
            "    print_board(board, n)\n",
            "    return True\n",
            "```\n",
            "\n",
            "This algorithm uses a recursive approach to solve the n-Queens problem. It starts by placing a queen in the first column of the first row, and then recursively places the queens in the remaining columns. If it finds a place where a queen can be placed without being attacked, it places a queen there and recursively tries to place the rest of the queens. If it can't find a place, it backtracks and removes the queen from the current column.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    { 'role': 'user', 'content': '''Write Pascal code in MODERN PASCAL syntax with the following requirement:\n",
        "    - MUST use inline variable declaration in FOR loops: \"for var i := 1 to n do\"\n",
        "    - Do NOT use traditional variable declaration before the loop\n",
        "    - This is for Free Pascal or PascalABC.NET compiler\n",
        "\n",
        "    Write a function that counts 'A' symbols in a string.'''}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=1024, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAhpUTtzOjFG",
        "outputId": "7db20f2b-079e-4f2d-eb17-d208a0a8a89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a simple function in Free Pascal that counts the number of 'A' symbols in a string:\n",
            "\n",
            "```pascal\n",
            "function CountA(const s: string): integer;\n",
            "var\n",
            "  i: integer;\n",
            "begin\n",
            "  Result := 0;\n",
            "  for i := 1 to length(s) do\n",
            "    if s[i] = 'A' then\n",
            "      Inc(Result);\n",
            "end;\n",
            "```\n",
            "\n",
            "This function takes a string as input and initializes a counter to 0. It then iterates over each character in the string, checking if it is 'A'. If it is, it increments the counter. Finally, it returns the counter, which represents the number of 'A' symbols in the string.\n",
            "\n",
            "Please note that this function is case-sensitive, meaning it will count 'A' and 'a' as the same symbol. If you want to count 'A' and 'a' as different symbols, you would need to convert the string to either lower or upper case before counting.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    { 'role': 'user', 'content': '''\n",
        "    Follow these rules when writing Pascal code:\n",
        "    - Use \"for var i := 1 to n do\" pattern instead of \"var i : integer; for i := 1 to n do\"\n",
        "\n",
        "    Translate this Python code to Pascal:\n",
        "    def is_attack(i, j):\n",
        "        # Check for any queen in the same row\n",
        "        for k in range(0, n):\n",
        "            if board[i][k] == 1:\n",
        "                return True\n",
        "\n",
        "        # Check for any queen in the same column\n",
        "        for k in range(0, n):\n",
        "            if board[k][j] == 1:\n",
        "                return True\n",
        "\n",
        "        # Check for any queen in the same diagonal\n",
        "        for k in range(0, n):\n",
        "            for l in range(0, n):\n",
        "                if (k + l == i + j) or (k - l == i - j):\n",
        "                    if board[k][l] == 1:\n",
        "                        return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def solve_n_queens_util(n, i):\n",
        "        # base case\n",
        "        if i == n:\n",
        "            return True\n",
        "\n",
        "        for j in range(0, n):\n",
        "            if not is_attack(i, j):\n",
        "                # place queen at board[i][j]\n",
        "                board[i][j] = 1\n",
        "\n",
        "                # recur to place rest of the queens\n",
        "                if solve_n_queens_util(n, i + 1) == True:\n",
        "                    return True\n",
        "\n",
        "                # If placing queen in board[i][j] doesn't lead to a solution, then\n",
        "                # remove queen from board[i][j]\n",
        "                board[i][j] = 0\n",
        "\n",
        "        return False\n",
        "\n",
        "    board = [[0]*n for _ in range(n)]\n",
        "\n",
        "    if solve_n_queens_util(n, 0) == False:\n",
        "        print(\"Solution does not exist\")\n",
        "        return False\n",
        "\n",
        "    print_board(board, n)\n",
        "    return True\n",
        "    '''}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jto0StQ3Jvg-",
        "outputId": "d4c97698-bce1-40bf-d48f-24ca1900ad8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the Pascal code equivalent to the given Python code:\n",
            "\n",
            "```pascal\n",
            "function is_attack(i, j: integer; n: integer): boolean;\n",
            "var\n",
            "  k: integer;\n",
            "begin\n",
            "  // Check for any queen in the same row\n",
            "  for k := 0 to n-1 do\n",
            "    if board[i][k] = 1 then\n",
            "      exit(true);\n",
            "\n",
            "  // Check for any queen in the same column\n",
            "  for k := 0 to n-1 do\n",
            "    if board[k][j] = 1 then\n",
            "      exit(true);\n",
            "\n",
            "  // Check for any queen in the same diagonal\n",
            "  for k := 0 to n-1 do\n",
            "    for l := 0 to n-1 do\n",
            "      if (k + l = i + j) or (k - l = i - j) then\n",
            "        if board[k][l] = 1 then\n",
            "          exit(true);\n",
            "\n",
            "  exit(false);\n",
            "end;\n",
            "\n",
            "function solve_n_queens_util(n, i: integer): boolean;\n",
            "var\n",
            "  j: integer;\n",
            "begin\n",
            "  // base case\n",
            "  if i = n then\n",
            "    exit(true);\n",
            "\n",
            "  for j := 0 to n-1 do\n",
            "    if not is_attack(i, j, n) then\n",
            "    begin\n",
            "      // place queen at board[i][j]\n",
            "      board[i][j] := 1;\n",
            "\n",
            "      // recur to place rest of the queens\n",
            "      if solve_n_queens_util(n, i + 1) then\n",
            "        exit(true);\n",
            "\n",
            "      // If placing queen in board[i][j] doesn't lead to a solution, then\n",
            "      // remove queen from board[i][j]\n",
            "      board[i][j] := 0;\n",
            "    end;\n",
            "\n",
            "  exit(false);\n",
            "end;\n",
            "\n",
            "var\n",
            "  board: array of array of integers;\n",
            "  n: integer;\n",
            "begin\n",
            "  n := 4;\n",
            "  setlength(board, n, n);\n",
            "\n",
            "  if solve_n_queens_util(n, 0) then\n",
            "    print_board(board, n)\n",
            "  else\n",
            "    writeln('Solution does not exist');\n",
            "end.\n",
            "```\n",
            "\n",
            "Please note that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = '''\n",
        "### Example 1: Factorial calculation\n",
        "### Instruction: Write factorial function in PascalABC.NET\n",
        "### Response:\n",
        "program FactorialExample;\n",
        "\n",
        "function Factorial(n: integer): integer;\n",
        "begin\n",
        "  if n <= 1 then\n",
        "    Result := 1\n",
        "  else\n",
        "    Result := n * Factorial(n - 1);\n",
        "end;\n",
        "\n",
        "begin\n",
        "  WriteLn('Factorial of 5 is ', Factorial(5));\n",
        "end.\n",
        "\n",
        "### Example 2: Fibonacci sequence\n",
        "### Instruction: Implement Fibonacci in PascalABC.NET\n",
        "### Response:\n",
        "program FibonacciExample;\n",
        "\n",
        "function Fibonacci(n: integer): integer;\n",
        "begin\n",
        "  if n <= 1 then\n",
        "    Result := n\n",
        "  else\n",
        "    Result := Fibonacci(n - 1) + Fibonacci(n - 2);\n",
        "end;\n",
        "\n",
        "begin\n",
        "  for var i := 0 to 10 do\n",
        "    WriteLn('Fib(', i, ') = ', Fibonacci(i));\n",
        "end.\n",
        "'''\n",
        "\n",
        "target_request = '''\n",
        "### Example 3: Tower of Hanoi\n",
        "### Instruction: Implement Tower of Hanoi algorithm in PascalABC.NET\n",
        "### Response:\n",
        "'''\n",
        "prompt = examples + target_request\n",
        "\n",
        "messages=[\n",
        "    { 'role': 'user', 'content': prompt}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUFR0-fCDK04",
        "outputId": "e1de017f-9154-446d-9a83-15d4e8dfff30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program HanoiExample;\n",
            "\n",
            "procedure Hanoi(n: integer; source, target, auxiliary: integer);\n",
            "begin\n",
            "  if n > 0 then\n",
            "  begin\n",
            "    Hanoi(n - 1, source, auxiliary, target);\n",
            "    WriteLn('Move disk ', n, ' from tower ', source, ' to tower ', target);\n",
            "    Hanoi(n - 1, auxiliary, target, source);\n",
            "  end;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  Hanoi(3, 1, 3, 2);\n",
            "end.\n",
            "\n",
            "This program will move the disks of a tower of 3 from tower 1 to tower 3 using tower 2 as the auxiliary peg. The procedure Hanoi is a recursive procedure that moves the n-1 disks from the source peg to the auxiliary peg, then moves the nth disk from the source peg to the target peg, and finally moves the n-1 disks from the auxiliary peg to the target peg.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = '''\n",
        "### Example 1: Array processing\n",
        "### Instruction: Find maximum element in array\n",
        "### Response:\n",
        "program FindMaxExample;\n",
        "\n",
        "function FindMax(arr: array of integer): integer;\n",
        "begin\n",
        "  Result := arr[0];\n",
        "  for var i := 1 to High(arr) do\n",
        "    if arr[i] > Result then\n",
        "      Result := arr[i];\n",
        "end;\n",
        "\n",
        "begin\n",
        "  var numbers := Arr(3, 7, 2, 9, 1);\n",
        "  WriteLn('Maximum is ', FindMax(numbers));\n",
        "end.\n",
        "\n",
        "### Example 2: Backtracking pattern\n",
        "### Instruction: Generate all permutations\n",
        "### Response:\n",
        "program PermutationsExample;\n",
        "\n",
        "procedure GeneratePermutations(arr: array of integer; start: integer);\n",
        "begin\n",
        "  if start = Length(arr) then\n",
        "  begin\n",
        "    // Process permutation\n",
        "    for var i := 0 to High(arr) do\n",
        "      Write(arr[i], ' ');\n",
        "    WriteLn;\n",
        "    Exit;\n",
        "  end;\n",
        "\n",
        "  for var i := start to High(arr) do\n",
        "  begin\n",
        "    Swap(arr[start], arr[i]);\n",
        "    GeneratePermutations(arr, start + 1);\n",
        "    Swap(arr[start], arr[i]); // backtrack\n",
        "  end;\n",
        "end;\n",
        "\n",
        "begin\n",
        "  var elements := Arr(1, 2, 3);\n",
        "  GeneratePermutations(elements, 0);\n",
        "end.\n",
        "'''\n",
        "\n",
        "target_request = '''\n",
        "### Example 3: N-Queens problem\n",
        "### Instruction: Solve N-Queens problem in PascalABC.NET\n",
        "### Response:\n",
        "'''\n",
        "prompt = examples + target_request\n",
        "\n",
        "messages=[\n",
        "    { 'role': 'user', 'content': prompt}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
        "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtLuTtyVEK_z",
        "outputId": "f64fa043-9aa2-4032-a4e1-0b84544f7afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The N-Queens problem is a classic problem in computer science and logic. It's a problem of placing N queens on an N×N chessboard such that no two queens threaten each other.\n",
            "\n",
            "Here is a simple solution in PascalABC.NET:\n",
            "\n",
            "```pascal\n",
            "program NQueens;\n",
            "\n",
            "function IsSafe(x, y: integer; var board: array of array of integer): boolean;\n",
            "begin\n",
            "  var i: integer;\n",
            "  for i := 0 to y - 1 do\n",
            "    if board[x][i] = 1 then\n",
            "      Exit(false);\n",
            "  for i := 0 to x - 1 do\n",
            "    if board[i][y] = 1 then\n",
            "      Exit(false);\n",
            "  for i := 0 to min(x, y) - 1 do\n",
            "    if board[x - i][y - i] = 1 then\n",
            "      Exit(false);\n",
            "  for i := 0 to min(x, y) - 1 do\n",
            "    if board[x - i][y + i] = 1 then\n",
            "      Exit(false);\n",
            "  Result := true;\n",
            "end;\n",
            "\n",
            "procedure PlaceQueen(x, y: integer; var board: array of array of integer);\n",
            "begin\n",
            "  if x = Length(board) then\n",
            "    Exit;\n",
            "  if IsSafe(x, y, board) then\n",
            "  begin\n",
            "    board[x][y] := 1;\n",
            "    if x = Length(board) - 1 then\n",
            "      WriteLn('Solution:')\n",
            "    else\n",
            "      PlaceQueen(x + 1, 0, board);\n",
            "    board[x][y] := 0;\n",
            "  end\n",
            "  else\n",
            "    PlaceQueen(x, y + 1, board);\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var board := Arr(\n",
            "    Arr(0, 0, 0, 0),\n",
            "    Arr(0, 0, 0, 0),\n",
            "    Arr(0, 0, 0, 0),\n",
            "    Arr(0, 0, 0, 0)\n",
            "  );\n",
            "  PlaceQueen(0, 0, board);\n",
            "end.\n",
            "```\n",
            "\n",
            "This program uses a recursive function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && python finetune_deepseekcoder2.py \\\n",
        "    --model_name_or_path deepseek-ai/deepseek-coder-1.3b-instruct \\\n",
        "    --data_path /content/train_data.json \\\n",
        "    --output_dir /content/drive/MyDrive/LoRa \\\n",
        "    --num_train_epochs 4 \\\n",
        "    --per_device_train_batch_size 8 \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 25 \\\n",
        "    --save_total_limit 4 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --warmup_steps 10 \\\n",
        "    --logging_steps 10 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --report_to \"tensorboard\" \\\n",
        "    --bf16 True \\\n",
        "    --model_max_length 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG-6Iz1jBx_u",
        "outputId": "870b58a2-388f-4b5a-c020-7081cec7cb00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-04 12:30:52.973627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762259452.993433    4496 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762259452.999578    4496 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762259453.015687    4496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762259453.015715    4496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762259453.015719    4496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762259453.015724    4496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-04 12:30:53.020299: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "====================================================================================================\n",
            "Training Arguments: TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "cache_dir=None,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/LoRa/runs/Nov04_12-30-59_59c1d87a1071,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "model_max_length=1024,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=4.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/LoRa,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=25,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=4,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=10,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "Model Arguments: ModelArguments(model_name_or_path='deepseek-ai/deepseek-coder-1.3b-instruct')\n",
            "Data Arguments: DataArguments(data_path='/content/train_data.json')\n",
            "PAD Token: <｜end▁of▁sentence｜> 32014\n",
            "BOS Token <｜begin▁of▁sentence｜> 32013\n",
            "EOS Token <|EOT|> 32021\n",
            "Load tokenizer from deepseek-ai/deepseek-coder-1.3b-instruct over.\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Load LoRa model from deepseek-ai/deepseek-coder-1.3b-instruct over.\n",
            "Training dataset samples: 1862\n",
            "Sample 1564 of the training set: [32013, 2042, 417, 245, 17530, 1048, 3323, 34, 13, 15465, 25419, 20391, 13, 23114, 1067, 6544, 25, 185, 16, 13, 17437, 885, 17530, 1048, 3323, 34, 13, 15465, 2974, 185, 17, 13, 10271, 543, 3928, 6602, 750, 2188, 185, 18, 13, 7310, 4946, 17530, 1048, 3323, 34, 13, 15465, 3792, 185, 13518, 3649, 3475, 25, 185, 3004, 3293, 274, 8073, 2040, 344, 7579, 2485, 3750, 280, 3857, 185, 13518, 21289, 25, 185, 3344, 13966, 7, 25446, 25, 3639, 13, 5055, 477, 8073, 6310, 1191, 28, 13966, 7, 25446, 477, 185, 32021], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3344, 13966, 7, 25446, 25, 3639, 13, 5055, 477, 8073, 6310, 1191, 28, 13966, 7, 25446, 477, 185, 32021].\n",
            "Sample 1564 of the training set: <｜begin▁of▁sentence｜>You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "### Instruction:\n",
            "Implement an extension method that returns low index of array\n",
            "### Response:\n",
            "function Low(Self: System.Array); extensionmethod := Low(Self);\n",
            "<|EOT|>.\n",
            "Sample 1839 of the training set: [32013, 2042, 417, 245, 17530, 1048, 3323, 34, 13, 15465, 25419, 20391, 13, 23114, 1067, 6544, 25, 185, 16, 13, 17437, 885, 17530, 1048, 3323, 34, 13, 15465, 2974, 185, 17, 13, 10271, 543, 3928, 6602, 750, 2188, 185, 18, 13, 7310, 4946, 17530, 1048, 3323, 34, 13, 15465, 3792, 185, 13518, 3649, 3475, 25, 185, 20068, 1043, 1889, 5046, 12959, 8073, 2040, 327, 5891, 27, 22599, 29, 185, 13518, 21289, 25, 185, 3344, 11324, 1043, 1889, 5046, 12959, 7, 25446, 25, 5891, 27, 22599, 29, 26, 3240, 25, 10878, 1191, 4084, 16, 15, 1772, 9263, 12959, 26, 185, 315, 8073, 6310, 1191, 28, 11324, 1043, 1889, 5046, 12959, 7, 25446, 11, 3240, 477, 185, 32021], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3344, 11324, 1043, 1889, 5046, 12959, 7, 25446, 25, 5891, 27, 22599, 29, 26, 3240, 25, 10878, 1191, 4084, 16, 15, 1772, 9263, 12959, 26, 185, 315, 8073, 6310, 1191, 28, 11324, 1043, 1889, 5046, 12959, 7, 25446, 11, 3240, 477, 185, 32021].\n",
            "Sample 1839 of the training set: <｜begin▁of▁sentence｜>You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "### Instruction:\n",
            "DigitsToBigInteger extension method for List<integer>\n",
            "### Response:\n",
            "function DigitsToBigInteger(Self: List<integer>; base: integer := 10): BigInteger;\n",
            "    extensionmethod := DigitsToBigInteger(Self, base);\n",
            "<|EOT|>.\n",
            "/content/finetune_deepseekcoder2.py:221: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 32014}.\n",
            "  0% 0/468 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "{'loss': 1.3177, 'grad_norm': 0.8636504411697388, 'learning_rate': 0.00018, 'epoch': 0.09}\n",
            "{'loss': 0.8448, 'grad_norm': 0.3297754228115082, 'learning_rate': 0.00019980950399213344, 'epoch': 0.17}\n",
            "{'loss': 0.751, 'grad_norm': 0.5793932676315308, 'learning_rate': 0.0001991519310044857, 'epoch': 0.26}\n",
            "{'loss': 0.7344, 'grad_norm': 0.49308353662490845, 'learning_rate': 0.00019802802122990758, 'epoch': 0.34}\n",
            "{'loss': 0.6166, 'grad_norm': 0.35534200072288513, 'learning_rate': 0.0001964430607023449, 'epoch': 0.43}\n",
            "{'loss': 0.704, 'grad_norm': 0.5207797884941101, 'learning_rate': 0.0001944045038948709, 'epoch': 0.52}\n",
            "{'loss': 0.589, 'grad_norm': 0.451993465423584, 'learning_rate': 0.0001919219386594007, 'epoch': 0.6}\n",
            "{'loss': 0.5877, 'grad_norm': 0.47076496481895447, 'learning_rate': 0.00018900704113258165, 'epoch': 0.69}\n",
            "{'loss': 0.6019, 'grad_norm': 0.4150058627128601, 'learning_rate': 0.00018567352081994852, 'epoch': 0.77}\n",
            "{'loss': 0.5583, 'grad_norm': 0.5436793565750122, 'learning_rate': 0.00018193705611662696, 'epoch': 0.86}\n",
            "{'loss': 0.5834, 'grad_norm': 0.5046440958976746, 'learning_rate': 0.0001778152205678477, 'epoch': 0.94}\n",
            "{'loss': 0.5179, 'grad_norm': 0.6585478782653809, 'learning_rate': 0.00017332740021608722, 'epoch': 1.03}\n",
            "{'loss': 0.4894, 'grad_norm': 0.6035610437393188, 'learning_rate': 0.00016849470242357196, 'epoch': 1.11}\n",
            "{'loss': 0.4268, 'grad_norm': 0.6270484924316406, 'learning_rate': 0.00016333985659897735, 'epoch': 1.2}\n",
            "{'loss': 0.4329, 'grad_norm': 0.8097900152206421, 'learning_rate': 0.00015788710729522953, 'epoch': 1.28}\n",
            "{'loss': 0.4426, 'grad_norm': 0.5758386850357056, 'learning_rate': 0.00015216210018119733, 'epoch': 1.37}\n",
            "{'loss': 0.4305, 'grad_norm': 0.5308370590209961, 'learning_rate': 0.00014619176142357935, 'epoch': 1.45}\n",
            "{'loss': 0.4265, 'grad_norm': 0.623923659324646, 'learning_rate': 0.0001400041710462833, 'epoch': 1.54}\n",
            "{'loss': 0.4104, 'grad_norm': 0.6725650429725647, 'learning_rate': 0.0001336284308629216, 'epoch': 1.63}\n",
            "{'loss': 0.4357, 'grad_norm': 0.6654787659645081, 'learning_rate': 0.00012709452760356884, 'epoch': 1.71}\n",
            "{'loss': 0.4272, 'grad_norm': 0.6288583874702454, 'learning_rate': 0.00012043319187953241, 'epoch': 1.8}\n",
            "{'loss': 0.501, 'grad_norm': 0.8006933927536011, 'learning_rate': 0.00011367575364946006, 'epoch': 1.88}\n",
            "{'loss': 0.4182, 'grad_norm': 0.5577176213264465, 'learning_rate': 0.00010685399486656406, 'epoch': 1.97}\n",
            "{'loss': 0.3654, 'grad_norm': 0.8297327160835266, 'learning_rate': 0.0001, 'epoch': 2.05}\n",
            "{'loss': 0.3642, 'grad_norm': 0.5360187292098999, 'learning_rate': 9.314600513343595e-05, 'epoch': 2.14}\n",
            "{'loss': 0.2783, 'grad_norm': 0.7276903390884399, 'learning_rate': 8.632424635053997e-05, 'epoch': 2.22}\n",
            "{'loss': 0.2916, 'grad_norm': 0.6804768443107605, 'learning_rate': 7.95668081204676e-05, 'epoch': 2.31}\n",
            "{'loss': 0.2997, 'grad_norm': 0.6807773113250732, 'learning_rate': 7.290547239643117e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3225, 'grad_norm': 0.7298992872238159, 'learning_rate': 6.637156913707839e-05, 'epoch': 2.48}\n",
            "{'loss': 0.2875, 'grad_norm': 0.5077753067016602, 'learning_rate': 5.9995828953716695e-05, 'epoch': 2.57}\n",
            "{'loss': 0.2491, 'grad_norm': 0.8094437122344971, 'learning_rate': 5.380823857642069e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2929, 'grad_norm': 0.6513176560401917, 'learning_rate': 4.783789981880267e-05, 'epoch': 2.74}\n",
            "{'loss': 0.2499, 'grad_norm': 0.8511507511138916, 'learning_rate': 4.211289270477047e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2862, 'grad_norm': 0.7304912805557251, 'learning_rate': 3.666014340102268e-05, 'epoch': 2.91}\n",
            "{'loss': 0.3211, 'grad_norm': 0.6858104467391968, 'learning_rate': 3.1505297576428075e-05, 'epoch': 3.0}\n",
            "{'loss': 0.2489, 'grad_norm': 0.6527148485183716, 'learning_rate': 2.667259978391281e-05, 'epoch': 3.08}\n",
            "{'loss': 0.241, 'grad_norm': 0.5811036825180054, 'learning_rate': 2.218477943215229e-05, 'epoch': 3.16}\n",
            "{'loss': 0.195, 'grad_norm': 0.5129151940345764, 'learning_rate': 1.806294388337305e-05, 'epoch': 3.25}\n",
            "{'loss': 0.2402, 'grad_norm': 0.5986002683639526, 'learning_rate': 1.43264791800515e-05, 'epoch': 3.33}\n",
            "{'loss': 0.1749, 'grad_norm': 0.835077166557312, 'learning_rate': 1.0992958867418357e-05, 'epoch': 3.42}\n",
            " 87% 407/468 [3:38:24<34:28, 33.91s/it]Traceback (most recent call last):\n",
            "  File \"/content/finetune_deepseekcoder2.py\", line 237, in <module>\n",
            "    train()\n",
            "  File \"/content/finetune_deepseekcoder2.py\", line 228, in train\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2325, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2674, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4020, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4110, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 819, in forward\n",
            "    return model_forward(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
            "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\", line 1850, in forward\n",
            "    return self.base_model(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n",
            "    return self.model.forward(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 918, in wrapper\n",
            "    output = func(self, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 459, in forward\n",
            "    outputs: BaseModelOutputWithPast = self.model(\n",
            "                                       ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 1064, in wrapper\n",
            "    outputs = func(self, *args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 395, in forward\n",
            "    hidden_states = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 93, in __call__\n",
            "    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py\", line 488, in checkpoint\n",
            "    return CheckpointFunction.apply(function, preserve, *args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\", line 576, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py\", line 262, in forward\n",
            "    outputs = run_function(*args)\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 294, in forward\n",
            "    hidden_states, _ = self.self_attn(\n",
            "                       ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 238, in forward\n",
            "    value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py\", line 771, in forward\n",
            "    result = result + lora_B(lora_A(dropout(x))) * scaling\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            " 87% 407/468 [3:38:26<32:44, 32.20s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем основную модель\n",
        "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
        "model2 = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Загружаем твои LoRA адаптеры\n",
        "model2 = PeftModel.from_pretrained(model2, \"/content/drive/MyDrive/LoRa\").to('cuda')\n",
        "\n",
        "# Загружаем токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Переводим в режим инференса\n",
        "model2.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c4c9b026ad524bd7ad8e193a69067460",
            "a428317e8fe84d0fae3446007e9f8673",
            "4e6c6ea332d544a9bb5b09b63465e4cf",
            "937d430ba31247faabea62e66c7c9ac8",
            "d93c9acb08db41b091030d9916afb45d",
            "8f86958cc9684d748ed7734d9244361f",
            "e4602b553824409c9fc73c3e24b764f1",
            "7229015f3bd344508928e60be7e919bc",
            "3322076c6ae0450b9e10c54ac7e6756e",
            "318df084a32d452e9d30ed2066192607",
            "18f5ced510754eb6b44a1b39b4d5b378",
            "1d421c6d4dfa4fd4b22ea24167b3bcc7",
            "1a2cad17aa6e4124819421093246d1d9",
            "e6ffc29d9f3043dd924bbd1f2f116d5e",
            "0b36e1a7926d4c8fb46f7cb8719c48b2",
            "017dc317a0c849aaa5e88e7dfa0b5c3e",
            "233da90970e046c88278a6c5ada28e96",
            "54e1b9c0432c4e93b45f480d6f9149f1",
            "36bd5d9b94964975b407781443cecddc",
            "c1734d752f9440a18a3846dd199c0763",
            "48b78a7930a54f7eb644f590db26ba70",
            "53964da667fa460dbfa408c55dbf0c29",
            "55678bd3780743c49d50711d7c2676d7",
            "31c485abb47043409863fa010ee065e5",
            "bcdf23462d8b4310b1050b11ed1e24d2",
            "52c464a5a7484a5bb964d4ad959b026b",
            "af87195123ca44b3aeed63760a476c7b",
            "e7f91048b41840d3aaee700ee32c929b",
            "94e29332ae4e4295b1efafd7df25e15e",
            "1b98e596defc412290cb00a6e43645ce",
            "4eaac59b11b74a919284bae1530d0d56",
            "640d878e43544ad1b699fc43010c7023",
            "406dcccc967e4452a2624ebdad146a21",
            "d3b76e103c954d22b7bf21e6ea4c7592",
            "4797988ab317430eb39a8d55edae4fbb",
            "986e76ae04dc456e8c04f39d7f49431e",
            "9147f0b63b734b078c7c5fbb6ebba034",
            "847fc16a99284813ad11f9d479acac50",
            "c6289b189e7b44febe4b5da9353195fe",
            "1fc0914f51a64e7bbea9fa7dfed28e8e",
            "8ef3a940a1cd4db9bcdb0027cf38228a",
            "b1966e6ba6ce4906bc9596d5c4a6be83",
            "cb2a3ca60b03478da6fe49a95211dc9f",
            "1318d0c28ccf4bb9a69746f284848cf5",
            "3953181544504c4a8b149fb26cb4f912",
            "05542fcb720d4d86b16c6e4651ef584a",
            "74c65882e0c94c6087a70f99afc994e0",
            "ac01751420e747c09a0c7e0ad9daadb1",
            "4cc1c5bbfbe4473492e2918d81dafdb3",
            "2c6432eb622b49aa94b0616be6d28ea6",
            "4516cf573e5448f99867a66d77bc1526",
            "8db923f6f9914c3eb4823e0e78d41a5e",
            "16381f8e44144c88b55b81722c560db8",
            "dca10175ced547a29581efee2757cba0",
            "0d849037614d435f830c13141060f466"
          ]
        },
        "id": "1OdXeRpYph_J",
        "outputId": "5e085729-a268-4f6c-8a4a-ae23d9bcf6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4c9b026ad524bd7ad8e193a69067460"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.69G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d421c6d4dfa4fd4b22ea24167b3bcc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55678bd3780743c49d50711d7c2676d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3b76e103c954d22b7bf21e6ea4c7592"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3953181544504c4a8b149fb26cb4f912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): ModulesToSaveWrapper(\n",
              "          (original_module): Embedding(32256, 2048)\n",
              "          (modules_to_save): ModuleDict(\n",
              "            (default): Embedding(32256, 2048)\n",
              "          )\n",
              "        )\n",
              "        (layers): ModuleList(\n",
              "          (0-23): 24 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=5504, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=5504, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=5504, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=5504, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=5504, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=5504, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=2048, out_features=32256, bias=False)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=2048, out_features=32256, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, prompt):\n",
        "    # Форматируем как при обучении\n",
        "    formatted_prompt = f'''\n",
        "You are a PascalABC.NET coding assistant. Follow these rules:\n",
        "1. Write only PascalABC.NET code\n",
        "2. Provide complete programs when possible\n",
        "3. Use modern PascalABC.NET features\n",
        "\n",
        "### Instruction:\n",
        "{prompt}\n",
        "### Response:\n",
        "'''\n",
        "\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1024,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "def test_model_raw(prompt):\n",
        "  formatted_prompt = f'''\n",
        "    ### Instruction:\n",
        "    {prompt}\n",
        "    ### Response:\n",
        "    '''\n",
        "\n",
        "  inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(model2.device)\n",
        "\n",
        "  print(f\"Inputs device: {inputs['input_ids'].device}\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model2.generate(\n",
        "          **inputs,\n",
        "          max_new_tokens=1024,\n",
        "          temperature=0.7,\n",
        "          do_sample=True,\n",
        "          pad_token_id=tokenizer.eos_token_id\n",
        "      )\n",
        "\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "2owFFgKQqtyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тест 1: Простая функция\n",
        "test_prompts = [\n",
        "    \"\"\"Напиши функцию для вычисления факториала числа\"\"\",\n",
        "\n",
        "    \"\"\"Напиши программу которая выводит все простые числа до 100\"\"\",\n",
        "\n",
        "    \"\"\"Создай класс \"Студент\" с полями: имя, возраст, средний балл\"\"\",\n",
        "\n",
        "    \"\"\"Напиши код для чтения данных из текстового файла и вывода содержимого\"\"\",\n",
        "\n",
        "    \"\"\"Реализуй алгоритм пузырьковой сортировки массива\"\"\"\n",
        "]\n",
        "\n",
        "# Запускаем тесты\n",
        "print(\"🧪 ТЕСТИРУЕМ МОДЕЛЬ...\\n\")\n",
        "for i, prompt in enumerate(test_prompts, 1):\n",
        "    print(f\"📝 Тест {i}: {prompt}\")\n",
        "    print(\"🔧 Ответ:\")\n",
        "    response = test_model(prompt)\n",
        "    # Показываем только часть после Response:\n",
        "    if \"### Response:\" in response:\n",
        "        response = response.split(\"### Response:\")[1].strip()\n",
        "    print(response)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6jbPt7qaoS",
        "outputId": "4f7b7aa1-5c24-4af2-890b-866d36f12411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 ТЕСТИРУЕМ МОДЕЛЬ...\n",
            "\n",
            "📝 Тест 1: Напиши функцию для вычисления факториала числа\n",
            "🔧 Ответ:\n",
            "function Factorial(n: integer): integer;\n",
            "begin\n",
            "  if n<0 then\n",
            "    Result := 1\n",
            "  else\n",
            "    Result := n * Factorial(n-1);\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var n := 20;\n",
            "  WritelnFormat('Факториал {0} равен {1}',n,Factorial(n));\n",
            "end.\n",
            "\n",
            "==================================================\n",
            "\n",
            "📝 Тест 2: Напиши программу которая выводит все простые числа до 100\n",
            "🔧 Ответ:\n",
            "// Простые числа до 100\n",
            "begin\n",
            "  for var i:=2 to 100 do\n",
            "  begin\n",
            "    var f:=True;\n",
            "    for var j:=2 to i.Sqrt.Trunc do\n",
            "      if i.Divs(j) then\n",
            "      begin\n",
            "        f:=False;\n",
            "        break;\n",
            "      end;\n",
            "    if f then\n",
            "      Print(i);\n",
            "  end;\n",
            "end.\n",
            "\n",
            "==================================================\n",
            "\n",
            "📝 Тест 3: Создай класс \"Студент\" с полями: имя, возраст, средний балл\n",
            "🔧 Ответ:\n",
            "type \n",
            "  Student = class\n",
            "    name,surname: string;\n",
            "    age,grade: integer;\n",
            "  end;\n",
            "\n",
            "begin\n",
            "  var s := new Student('Иванов','Иван',20,87);\n",
            "  s.Print;\n",
            "end.\n",
            "\n",
            "==================================================\n",
            "\n",
            "📝 Тест 4: Напиши код для чтения данных из текстового файла и вывода содержимого\n",
            "🔧 Ответ:\n",
            "var \n",
            "  f: Text;\n",
            "  s: string;\n",
            "begin\n",
            "  assign(f,'a.txt');\n",
            "  reset(f);\n",
            "  while not eoln(f) do\n",
            "  begin\n",
            "    readln(f,s);\n",
            "    writeln(s);\n",
            "  end;\n",
            "  close(f);\n",
            "end.\n",
            "\n",
            "==================================================\n",
            "\n",
            "📝 Тест 5: Реализуй алгоритм пузырьковой сортировки массива\n",
            "🔧 Ответ:\n",
            "procedure BubbleSort(a: array of real);\n",
            "begin\n",
            "  for var i:=0 to a.Length-2 do\n",
            "  begin\n",
            "    for var j:=0 to a.Length-2-i do\n",
            "    begin\n",
            "      if a[j]>a[j+1] then\n",
            "      begin\n",
            "        Swap(a[j],a[j+1]);\n",
            "      end;\n",
            "    end;\n",
            "  end;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var a := ArrRandom(10);\n",
            "  Println('До сортировки: ');\n",
            "  Println(a);\n",
            "  BubbleSort(a);\n",
            "  Println('После сортировки: ');\n",
            "  Println(a);\n",
            "end.\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(\"Выведи 2-у декартову степень множества символов, задаваемого строкой 'xyzw'\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np74htrI1v1T",
        "outputId": "d499e5d8-8fc1-4fd2-9353-e40432ff0fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs device: cuda:0\n",
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Выведи 2-у декартову степень множества символов, задаваемого строкой 'xyzw'\n",
            "### Response:\n",
            "begin\n",
            "  var s := 'xyzw';\n",
            "  var d := '';\n",
            "  foreach var c in s do\n",
            "    d += c + c;\n",
            "  Println(d);\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(\"Выведи 2-у декартову степень множества символов, задаваемого строкой 'xyzw'\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8YWLRuF2zSl",
        "outputId": "0659adee-57c1-4b14-d55e-af9b0b2c2e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Выведи 2-у декартову степень множества символов, задаваемого строкой 'xyzw'\n",
            "### Response:\n",
            "begin\n",
            "  var s := 'xyzw';\n",
            "  s.ToD2.Println;\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(\"Print the Cartesian square of the character set from the string 'xyzw'\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YKYEAse1rv3",
        "outputId": "819e5a77-f2ba-4e83-d848-05bf38311e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs device: cuda:0\n",
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Print the Cartesian square of the character set from the string 'xyzw'\n",
            "### Response:\n",
            "uses GraphABC;\n",
            "\n",
            "begin\n",
            "  var s := 'xyzw';\n",
            "  var max := Max(s);\n",
            "  var r := 10.0;\n",
            "  var dx := 2 * r;\n",
            "  var dy := r;\n",
            "  Rectangle(-r, -r, r*2+1, r+1);\n",
            "  foreach var c in s do\n",
            "  begin\n",
            "    var x := r;\n",
            "    var y := r;\n",
            "    var q := True;\n",
            "    case c of\n",
            "      'x': (x,y) := (x+dx,y);\n",
            "      'y': (x,y) := (x,y+dy);\n",
            "      'z': (x,y) := (x+dx*5,y);\n",
            "      'w': (x,y) := (x,y+dy*5);\n",
            "    end;\n",
            "    if q then\n",
            "      Circle(x,y,r);\n",
            "    TextOut(x,y,c);\n",
            "  end;\n",
            "  max += max*2;\n",
            "  TextOut(max*2,0,'After');\n",
            "  max += max*2;\n",
            "  TextOut(0,max*2,'After');\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(\"Напиши код, решающий задачу Ханойских башен с визуализацией при помощи библиотеки GraphABC\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYA9F6aP3GMc",
        "outputId": "ac4ead04-881c-4f0f-c495-1d04f7385a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs device: cuda:0\n",
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Напиши код, решающий задачу Ханойских башен с визуализацией при помощи библиотеки GraphABC\n",
            "### Response:\n",
            "uses GraphABC;\n",
            "\n",
            "procedure MoveFigure(n: integer; from, to, via: Rectangle);\n",
            "begin\n",
            "  if n > 1 then\n",
            "    MoveFigure(n-1, via, to, from);\n",
            "  via.MoveTo(to.Left, to.Top);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left + 60, from.Top + 60);\n",
            "  via.LineTo(from.Left + 60, from.Top);\n",
            "  via.LineTo(from.Left + 60, from.Top - 60);\n",
            "  via.LineTo(from.Left + 60, from.Top - 60);\n",
            "  via.LineTo(from.Left + 60, from.Top);\n",
            "  via.LineTo(from.Left + 60, from.Top + 60);\n",
            "  via.LineTo(from.Left + 60, from.Top + 60);\n",
            "  via.LineTo(from.Left + 60, from.Top);\n",
            "  via.LineTo(from.Left + 60, from.Top - 60);\n",
            "  via.LineTo(from.Left + 60, from.Top - 60);\n",
            "  via.LineTo(from.Left + 60, from.Top);\n",
            "  via.LineTo(from.Left + 60, from.Top + 60);\n",
            "  via.LineTo(from.Left + 60, from.Top + 60);\n",
            "  via.LineTo(from.Left + 60, from.Top);\n",
            "  via.LineTo(from.Left + 60, from.Top - 60);\n",
            "  via.LineTo(from.Left + 60, from.Top - 60);\n",
            "  via.LineTo(from.Left + 60, from.Top);\n",
            "  via.LineTo(from.Left + 60, from.Top + 60);\n",
            "  via.LineTo(from.Left + 60, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top - 60);\n",
            "  via.LineTo(from.Left, from.Top);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "  via.LineTo(from.Left, from.Top + 60);\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model_raw(\"Implement Tower of Hanoi algorithm\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0zlBkWc7kZL",
        "outputId": "49bfb517-76c9-4670-934b-8d81ac6ac805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs device: cuda:0\n",
            "\n",
            "    ### Instruction:\n",
            "    Implement Tower of Hanoi algorithm\n",
            "    ### Response:\n",
            "    \n",
            "    def hanoi(n, source, helper, target):\n",
            "        if n > 0:\n",
            "            hanoi(n - 1, source, target, helper)\n",
            "            move(source, target)\n",
            "            hanoi(n - 1, helper, source, target)\n",
            "    \n",
            "    def move(from_rod, to_rod):\n",
            "        print('move disc from rod', from_rod, 'to rod', to_rod)\n",
            "\n",
            "    n = 3\n",
            "    hanoi(n, 'A', 'B', 'C')\n",
            "    ### End: Implement Tower of Hanoi algorithm\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    ###\n",
            "    #\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate_prompt = f\"\"\"\n",
        "Translate this Python code to PascalABC.NET:\n",
        "\n",
        "Python code:\n",
        "def hanoi(n, source, helper, target):\n",
        "    if n > 0:\n",
        "        hanoi(n - 1, source, target, helper)\n",
        "        move(source, target)\n",
        "        hanoi(n - 1, helper, source, target)\n",
        "\n",
        "def move(from_rod, to_rod):\n",
        "    print('move disc from rod', from_rod, 'to rod', to_rod)\n",
        "\n",
        "n = 3\n",
        "hanoi(n, 'A', 'B', 'C')\n",
        "\n",
        "PascalABC.NET requirements:\n",
        "- Use modern PascalABC.NET syntax\n",
        "- Make it a complete program\n",
        "- Do not change parameters order\n",
        "\"\"\"\n",
        "\n",
        "print(test_model_raw(translate_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkAcLhMP1c64",
        "outputId": "330b189a-55de-4d1d-c155-856b58e1f91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs device: cuda:0\n",
            "\n",
            "    ### Instruction:\n",
            "    \n",
            "Translate this Python code to PascalABC.NET:\n",
            "\n",
            "Python code:\n",
            "def hanoi(n, source, helper, target):\n",
            "    if n > 0:\n",
            "        hanoi(n - 1, source, target, helper)\n",
            "        move(source, target)\n",
            "        hanoi(n - 1, helper, source, target)\n",
            "\n",
            "def move(from_rod, to_rod):\n",
            "    print('move disc from rod', from_rod, 'to rod', to_rod)\n",
            "\n",
            "n = 3\n",
            "hanoi(n, 'A', 'B', 'C')\n",
            "\n",
            "PascalABC.NET requirements:\n",
            "- Use modern PascalABC.NET syntax\n",
            "- Make it a complete program\n",
            "- Do not change parameters order\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "procedure Move(from_rod, to_rod: string);\n",
            "begin\n",
            "  Write('move disc from rod ',from_rod,' to rod ',to_rod);\n",
            "  NewLine;  \n",
            "end;\n",
            "\n",
            "procedure hanoi(n: integer; source, helper, target: string);\n",
            "begin\n",
            "  if n > 1 then\n",
            "  begin\n",
            "    hanoi(n-1, source, target, helper);\n",
            "    Move(source, target);\n",
            "    hanoi(n-1, helper, source, target);\n",
            "  end;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var n := 3;\n",
            "  hanoi(n, 'A', 'B', 'C');\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model_raw(\"Write an algorithm which solves n qweens problem in Python\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tkNddt6COC8",
        "outputId": "bc0a8a5e-cd23-4c4f-935b-7f45de690e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs device: cuda:0\n",
            "\n",
            "    ### Instruction:\n",
            "    Write an algorithm which solves n qweens problem in Python\n",
            "    ### Response:\n",
            "    \n",
            "    def solve_n_queens(n):\n",
            "        def can_place(queens, x, y):\n",
            "            for i in range(len(queens)):\n",
            "                if (queens[i] == y) or (queens[i] - x == y - queens[i]) or (queens[i] + x == y + queens[i]):\n",
            "                    return False\n",
            "            return True\n",
            "\n",
            "        def place_queen(n, queens, x):\n",
            "            for y in range(n):\n",
            "                if can_place(queens, x, y):\n",
            "                    if x == n-1:\n",
            "                        print_board(n, queens)\n",
            "                    else:\n",
            "                        place_queen(n, queens + [y], x + 1)\n",
            "\n",
            "        place_queen(n, [], 0)\n",
            "    ### End of solution\n",
            "\n",
            "    solve_n_queens(4)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(\"Напиши функцию быстрой сортировки\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsKAP5gt7fZb",
        "outputId": "540ccfe3-3077-4412-a6bd-7f6b31a820cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Напиши функцию быстрой сортировки\n",
            "### Response:\n",
            "function QSort(a: array of real): array of real;\n",
            "begin\n",
            "  if a.Length = 0 then\n",
            "    exit(a);\n",
            "  var pivot := a[0];\n",
            "  var less := a.Where(y->y<pivot);\n",
            "  var greater := a.Where(y->y>pivot);\n",
            "  Result := QSort(less);\n",
            "  Result += pivot;\n",
            "  Result += QSort(greater);\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var a := ArrRandom(20);\n",
            "  a.Println;\n",
            "  a := QSort(a);\n",
            "  a.Println;\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del model\n",
        "del model2\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb-BvNvdLvC1",
        "outputId": "5ca77375-bcb5-458a-a7e4-d627c04b993b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "975"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && python finetune_deepseekcoder3.py \\\n",
        "    --model_name_or_path deepseek-ai/deepseek-coder-1.3b-instruct \\\n",
        "    --data_path /content/train_data.json \\\n",
        "    --output_dir /content/drive/MyDrive/LoRaDifferentRank \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --per_device_train_batch_size 8 \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 100 \\\n",
        "    --save_total_limit 3 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --warmup_steps 10 \\\n",
        "    --logging_steps 10 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --report_to \"tensorboard\" \\\n",
        "    --bf16 True \\\n",
        "    --model_max_length 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCAcE7j8Izor",
        "outputId": "dad95329-7373-46b3-9e35-072284b43858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-27 15:38:01.980042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761579481.999616    1407 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761579482.005619    1407 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761579482.020374    1407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761579482.020396    1407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761579482.020400    1407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761579482.020405    1407 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-27 15:38:02.024816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "====================================================================================================\n",
            "Training Arguments: TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "cache_dir=None,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/LoRaDifferentRank/runs/Oct27_15-38-09_9aabcb0e2ef5,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "model_max_length=1024,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/LoRaDifferentRank,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=10,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "Model Arguments: ModelArguments(model_name_or_path='deepseek-ai/deepseek-coder-1.3b-instruct')\n",
            "Data Arguments: DataArguments(data_path='/content/train_data.json')\n",
            "tokenizer_config.json: 1.87kB [00:00, 10.1MB/s]\n",
            "tokenizer.json: 1.37MB [00:00, 54.5MB/s]\n",
            "PAD Token: <｜end▁of▁sentence｜> 32014\n",
            "BOS Token <｜begin▁of▁sentence｜> 32013\n",
            "EOS Token <|EOT|> 32021\n",
            "Load tokenizer from deepseek-ai/deepseek-coder-1.3b-instruct over.\n",
            "config.json: 100% 631/631 [00:00<00:00, 5.33MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors: 100% 2.69G/2.69G [00:58<00:00, 46.4MB/s]\n",
            "generation_config.json: 100% 119/119 [00:00<00:00, 850kB/s]\n",
            "Load LoRa model from deepseek-ai/deepseek-coder-1.3b-instruct over.\n",
            "Generating train split: 1862 examples [00:00, 31945.43 examples/s]\n",
            "Running Encoding (num_proc=4): 100% 1862/1862 [00:04<00:00, 394.59 examples/s]\n",
            "Training dataset samples: 1862\n",
            "Sample 1725 of the training set: [32013, 2042, 417, 245, 17530, 1048, 3323, 34, 13, 15465, 25419, 20391, 13, 23114, 1067, 6544, 25, 185, 16, 13, 17437, 885, 17530, 1048, 3323, 34, 13, 15465, 2974, 185, 17, 13, 10271, 543, 3928, 6602, 750, 2188, 185, 18, 13, 7310, 4946, 17530, 1048, 3323, 34, 13, 15465, 3792, 185, 13518, 3649, 3475, 25, 185, 3004, 3293, 8073, 4775, 327, 1315, 20365, 272, 280, 2232, 304, 308, 7373, 26844, 14154, 26844, 185, 13518, 21289, 25, 185, 3344, 3639, 11291, 575, 45, 16, 27, 51, 29, 7, 25446, 25, 3857, 58, 11, 60, 280, 323, 26, 12812, 284, 25, 3857, 280, 9284, 575, 1920, 1772, 3857, 280, 323, 26, 8073, 6310, 207, 185, 207, 1191, 28, 9284, 575, 45, 7, 25446, 11, 75, 8, 372, 3857, 280, 323, 26, 185, 185, 3344, 3639, 11291, 575, 45, 16, 27, 51, 29, 7, 25446, 25, 3857, 58, 19555, 60, 280, 323, 26, 12812, 284, 25, 3857, 280, 9284, 575, 1920, 1772, 3857, 280, 323, 26, 8073, 6310, 207, 185, 207, 1191, 28, 9284, 575, 45, 7, 25446, 11, 75, 8, 372, 3857, 280, 323, 26, 185, 185, 3344, 3639, 11291, 575, 45, 16, 27, 51, 29, 7, 25446, 25, 3857, 58, 19555, 11, 60, 280, 323, 26, 12812, 284, 25, 3857, 280, 9284, 575, 1920, 1772, 3857, 280, 323, 26, 8073, 6310, 207, 185, 207, 1191, 28, 9284, 575, 45, 7, 25446, 11, 75, 8, 372, 3857, 280, 323, 26, 185, 32021], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3344, 3639, 11291, 575, 45, 16, 27, 51, 29, 7, 25446, 25, 3857, 58, 11, 60, 280, 323, 26, 12812, 284, 25, 3857, 280, 9284, 575, 1920, 1772, 3857, 280, 323, 26, 8073, 6310, 207, 185, 207, 1191, 28, 9284, 575, 45, 7, 25446, 11, 75, 8, 372, 3857, 280, 323, 26, 185, 185, 3344, 3639, 11291, 575, 45, 16, 27, 51, 29, 7, 25446, 25, 3857, 58, 19555, 60, 280, 323, 26, 12812, 284, 25, 3857, 280, 9284, 575, 1920, 1772, 3857, 280, 323, 26, 8073, 6310, 207, 185, 207, 1191, 28, 9284, 575, 45, 7, 25446, 11, 75, 8, 372, 3857, 280, 323, 26, 185, 185, 3344, 3639, 11291, 575, 45, 16, 27, 51, 29, 7, 25446, 25, 3857, 58, 19555, 11, 60, 280, 323, 26, 12812, 284, 25, 3857, 280, 9284, 575, 1920, 1772, 3857, 280, 323, 26, 8073, 6310, 207, 185, 207, 1191, 28, 9284, 575, 45, 7, 25446, 11, 75, 8, 372, 3857, 280, 323, 26, 185, 32021].\n",
            "Sample 1725 of the training set: <｜begin▁of▁sentence｜>You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "### Instruction:\n",
            "Implement extension methods for system slicing of multidimensional arrays returning arrays\n",
            "### Response:\n",
            "function SystemSliceN1<T>(Self: array[,] of T; params l: array of SliceType): array of T; extensionmethod \n",
            "  := SliceN(Self,l) as array of T;\n",
            "\n",
            "function SystemSliceN1<T>(Self: array[,,] of T; params l: array of SliceType): array of T; extensionmethod \n",
            "  := SliceN(Self,l) as array of T;\n",
            "\n",
            "function SystemSliceN1<T>(Self: array[,,,] of T; params l: array of SliceType): array of T; extensionmethod \n",
            "  := SliceN(Self,l) as array of T;\n",
            "<|EOT|>.\n",
            "Sample 280 of the training set: [32013, 2042, 417, 245, 17530, 1048, 3323, 34, 13, 15465, 25419, 20391, 13, 23114, 1067, 6544, 25, 185, 16, 13, 17437, 885, 17530, 1048, 3323, 34, 13, 15465, 2974, 185, 17, 13, 10271, 543, 3928, 6602, 750, 2188, 185, 18, 13, 7310, 4946, 17530, 1048, 3323, 34, 13, 15465, 3792, 185, 13518, 3649, 3475, 25, 185, 7256, 245, 5621, 1719, 8215, 327, 254, 25995, 710, 757, 279, 17530, 1048, 3323, 34, 13, 15465, 344, 9132, 16018, 6084, 2023, 13, 428, 8215, 1020, 8891, 13668, 8103, 365, 4052, 10878, 15867, 13, 185, 13518, 21289, 25, 185, 667, 27490, 6518, 19941, 710, 7, 82, 25, 2600, 26, 245, 25, 2482, 280, 10878, 26, 15867, 25, 2482, 280, 10878, 477, 185, 553, 245, 567, 16018, 14250, 26, 185, 553, 245, 295, 1458, 567, 6129, 280, 5467, 5552, 26, 185, 946, 185, 207, 2241, 269, 43, 25, 28, 1829, 25995, 710, 7, 64, 477, 185, 207, 2241, 427, 25, 28, 78, 43, 13, 37, 9639, 938, 26, 185, 207, 2241, 427, 16, 25, 28, 81, 13, 24045, 13, 6330, 11587, 7, 87, 12, 29, 87, 477, 185, 207, 2241, 363, 7648, 25, 28, 82, 10, 4150, 2179, 4677, 10, 4843, 1027, 10, 81, 16, 13, 17083, 3373, 78, 2005, 10, 4150, 4492, 6, 10, 4843, 6498, 10, 185, 730, 15867, 13, 17083, 3373, 78, 2005, 10, 4150, 4052, 4057, 185, 207, 562, 427, 16, 13, 5611, 28, 295, 1458, 13, 5611, 930, 3473, 185, 315, 2241, 252, 16, 25, 28, 81, 16, 13, 57, 515, 7, 295, 1458, 21958, 72, 11, 73, 6906, 29, 72, 12, 73, 628, 12133, 26, 185, 315, 13326, 7, 82, 16, 28, 15, 11, 16626, 8, 185, 315, 1223, 185, 207, 1969, 185, 315, 13326, 7, 6082, 11, 16626, 8, 185, 408, 26, 185, 32021], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 667, 27490, 6518, 19941, 710, 7, 82, 25, 2600, 26, 245, 25, 2482, 280, 10878, 26, 15867, 25, 2482, 280, 10878, 477, 185, 553, 245, 567, 16018, 14250, 26, 185, 553, 245, 295, 1458, 567, 6129, 280, 5467, 5552, 26, 185, 946, 185, 207, 2241, 269, 43, 25, 28, 1829, 25995, 710, 7, 64, 477, 185, 207, 2241, 427, 25, 28, 78, 43, 13, 37, 9639, 938, 26, 185, 207, 2241, 427, 16, 25, 28, 81, 13, 24045, 13, 6330, 11587, 7, 87, 12, 29, 87, 477, 185, 207, 2241, 363, 7648, 25, 28, 82, 10, 4150, 2179, 4677, 10, 4843, 1027, 10, 81, 16, 13, 17083, 3373, 78, 2005, 10, 4150, 4492, 6, 10, 4843, 6498, 10, 185, 730, 15867, 13, 17083, 3373, 78, 2005, 10, 4150, 4052, 4057, 185, 207, 562, 427, 16, 13, 5611, 28, 295, 1458, 13, 5611, 930, 3473, 185, 315, 2241, 252, 16, 25, 28, 81, 16, 13, 57, 515, 7, 295, 1458, 21958, 72, 11, 73, 6906, 29, 72, 12, 73, 628, 12133, 26, 185, 315, 13326, 7, 82, 16, 28, 15, 11, 16626, 8, 185, 315, 1223, 185, 207, 1969, 185, 315, 13326, 7, 6082, 11, 16626, 8, 185, 408, 26, 185, 32021].\n",
            "Sample 280 of the training set: <｜begin▁of▁sentence｜>You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "### Instruction:\n",
            "Create a unit test procedure for the Factors class in PascalABC.NET that tests polynomial factorization. The procedure should compare computed factors with expected integer roots.\n",
            "### Response:\n",
            "procedure TestFactors(s:string; a:array of integer; roots:array of integer);\n",
            "// a - polynomial coefficients;\n",
            "// aroots - vector of reference solutions;\n",
            "begin\n",
            "  var oL:=new Factors(a);\n",
            "  var r:=oL.Factorize;\n",
            "  var r1:=r.Rows.SelectMany(x->x);\n",
            "  var Msg:=s+': error.'+Newline+r1.JoinIntoString+': received'+NewLine+\n",
            "      roots.JoinIntoString+': expected';\n",
            "  if r1.Count=roots.Count then begin\n",
            "    var s1:=r1.Zip(roots,(i,j)->i-j).Sum;\n",
            "    Assert(s1=0,Msg)\n",
            "    end\n",
            "  else\n",
            "    Assert(false,Msg)\n",
            "end;\n",
            "<|EOT|>.\n",
            "/content/finetune_deepseekcoder3.py:231: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 32014}.\n",
            "  0% 0/585 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "{'loss': 1.3346, 'grad_norm': 0.7708277702331543, 'learning_rate': 0.00018, 'epoch': 0.09}\n",
            "{'loss': 0.8936, 'grad_norm': 0.31497129797935486, 'learning_rate': 0.00019987912636893745, 'epoch': 0.17}\n",
            "{'loss': 0.7815, 'grad_norm': 0.5927739143371582, 'learning_rate': 0.00019946166673292344, 'epoch': 0.26}\n",
            "{'loss': 0.7646, 'grad_norm': 0.4617306888103485, 'learning_rate': 0.00019874737439152748, 'epoch': 0.34}\n",
            "{'loss': 0.6485, 'grad_norm': 0.338471919298172, 'learning_rate': 0.00019773838107383767, 'epoch': 0.43}\n",
            "{'loss': 0.74, 'grad_norm': 0.48705264925956726, 'learning_rate': 0.000196437698012483, 'epoch': 0.52}\n",
            "{'loss': 0.6235, 'grad_norm': 0.4221646189689636, 'learning_rate': 0.00019484920695693174, 'epoch': 0.6}\n",
            "{'loss': 0.6217, 'grad_norm': 0.45183467864990234, 'learning_rate': 0.00019297764858882514, 'epoch': 0.69}\n",
            "{'loss': 0.6316, 'grad_norm': 0.4045025706291199, 'learning_rate': 0.00019082860837392037, 'epoch': 0.77}\n",
            "{'loss': 0.596, 'grad_norm': 0.5358085632324219, 'learning_rate': 0.00018840849989286532, 'epoch': 0.86}\n",
            "{'loss': 0.613, 'grad_norm': 0.519372820854187, 'learning_rate': 0.0001857245457005532, 'epoch': 0.94}\n",
            "{'loss': 0.5592, 'grad_norm': 0.6805208325386047, 'learning_rate': 0.00018278475577118, 'epoch': 1.03}\n",
            "{'loss': 0.5425, 'grad_norm': 0.6210260391235352, 'learning_rate': 0.00017959790359333347, 'epoch': 1.11}\n",
            "{'loss': 0.4783, 'grad_norm': 0.6754288673400879, 'learning_rate': 0.00017617349998645456, 'epoch': 1.2}\n",
            "{'loss': 0.4825, 'grad_norm': 0.8516041040420532, 'learning_rate': 0.00017252176471681453, 'epoch': 1.28}\n",
            "{'loss': 0.487, 'grad_norm': 0.6330865621566772, 'learning_rate': 0.0001686535959977152, 'epoch': 1.37}\n",
            "{'loss': 0.4771, 'grad_norm': 0.5840286612510681, 'learning_rate': 0.0001645805379649377, 'epoch': 1.45}\n",
            "{'loss': 0.4773, 'grad_norm': 0.6778152585029602, 'learning_rate': 0.00016031474622450344, 'epoch': 1.54}\n",
            "{'loss': 0.4555, 'grad_norm': 0.7560096383094788, 'learning_rate': 0.00015586895157556854, 'epoch': 1.63}\n",
            "{'loss': 0.479, 'grad_norm': 0.7851932048797607, 'learning_rate': 0.0001512564220167154, 'epoch': 1.71}\n",
            "{'loss': 0.472, 'grad_norm': 0.7284525036811829, 'learning_rate': 0.00014649092314903016, 'epoch': 1.8}\n",
            "{'loss': 0.5396, 'grad_norm': 0.9049028754234314, 'learning_rate': 0.00014158667709413876, 'epoch': 1.88}\n",
            "{'loss': 0.4581, 'grad_norm': 0.6214507818222046, 'learning_rate': 0.00013655832004980608, 'epoch': 1.97}\n",
            "{'loss': 0.4144, 'grad_norm': 0.9314387440681458, 'learning_rate': 0.00013142085860976948, 'epoch': 2.05}\n",
            "{'loss': 0.4124, 'grad_norm': 0.6244158148765564, 'learning_rate': 0.0001261896249781647, 'epoch': 2.14}\n",
            "{'loss': 0.3283, 'grad_norm': 0.9124707579612732, 'learning_rate': 0.00012088023121220306, 'epoch': 2.22}\n",
            "{'loss': 0.3408, 'grad_norm': 0.81087726354599, 'learning_rate': 0.00011550852262965622, 'epoch': 2.31}\n",
            "{'loss': 0.3589, 'grad_norm': 0.8134746551513672, 'learning_rate': 0.00011009053052020047, 'epoch': 2.39}\n",
            "{'loss': 0.3823, 'grad_norm': 0.8686882257461548, 'learning_rate': 0.00010464242430174737, 'epoch': 2.48}\n",
            "{'loss': 0.3406, 'grad_norm': 0.5851359367370605, 'learning_rate': 9.918046326454568e-05, 'epoch': 2.57}\n",
            "{'loss': 0.3049, 'grad_norm': 0.9066770076751709, 'learning_rate': 9.372094804706867e-05, 'epoch': 2.65}\n",
            "{'loss': 0.3468, 'grad_norm': 0.7234693765640259, 'learning_rate': 8.828017198850227e-05, 'epoch': 2.74}\n",
            "{'loss': 0.295, 'grad_norm': 1.0485973358154297, 'learning_rate': 8.287437250301709e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3427, 'grad_norm': 0.8869693279266357, 'learning_rate': 7.75196826209427e-05, 'epoch': 2.91}\n",
            "{'loss': 0.3718, 'grad_norm': 0.8375024199485779, 'learning_rate': 7.223208284146421e-05, 'epoch': 3.0}\n",
            "{'loss': 0.2928, 'grad_norm': 0.8703582882881165, 'learning_rate': 6.702735344053187e-05, 'epoch': 3.08}\n",
            "{'loss': 0.286, 'grad_norm': 0.7070981860160828, 'learning_rate': 6.192102737631551e-05, 'epoch': 3.16}\n",
            "{'loss': 0.2358, 'grad_norm': 0.6362365484237671, 'learning_rate': 5.692834393275226e-05, 'epoch': 3.25}\n",
            "{'loss': 0.2821, 'grad_norm': 0.7905590534210205, 'learning_rate': 5.206420323953374e-05, 'epoch': 3.33}\n",
            "{'loss': 0.2167, 'grad_norm': 1.1049106121063232, 'learning_rate': 4.7343121804262894e-05, 'epoch': 3.42}\n",
            "{'loss': 0.2893, 'grad_norm': 0.8397937417030334, 'learning_rate': 4.277918918948973e-05, 'epoch': 3.51}\n",
            "{'loss': 0.2755, 'grad_norm': 0.8298590183258057, 'learning_rate': 3.838602596391895e-05, 'epoch': 3.59}\n",
            "{'loss': 0.2495, 'grad_norm': 0.6736112236976624, 'learning_rate': 3.4176743053279706e-05, 'epoch': 3.68}\n",
            "{'loss': 0.2955, 'grad_norm': 1.0395795106887817, 'learning_rate': 3.016390261217008e-05, 'epoch': 3.76}\n",
            "{'loss': 0.2889, 'grad_norm': 0.8275790810585022, 'learning_rate': 2.6359480533650505e-05, 'epoch': 3.85}\n",
            "{'loss': 0.2659, 'grad_norm': 0.9305456280708313, 'learning_rate': 2.2774830708471774e-05, 'epoch': 3.94}\n",
            "{'loss': 0.2468, 'grad_norm': 0.6978964805603027, 'learning_rate': 1.9420651140602697e-05, 'epoch': 4.02}\n",
            "{'loss': 0.2221, 'grad_norm': 0.8040451407432556, 'learning_rate': 1.6306952020181577e-05, 'epoch': 4.1}\n",
            "{'loss': 0.2353, 'grad_norm': 0.7633002996444702, 'learning_rate': 1.3443025849174484e-05, 'epoch': 4.19}\n",
            "{'loss': 0.1996, 'grad_norm': 0.8711346387863159, 'learning_rate': 1.0837419708896979e-05, 'epoch': 4.27}\n",
            "{'loss': 0.2155, 'grad_norm': 1.0231677293777466, 'learning_rate': 8.49790975216439e-06, 'epoch': 4.36}\n",
            "{'loss': 0.2007, 'grad_norm': 1.146691918373108, 'learning_rate': 6.431477996195357e-06, 'epoch': 4.45}\n",
            "{'loss': 0.2459, 'grad_norm': 0.7503048777580261, 'learning_rate': 4.644291485528362e-06, 'epoch': 4.53}\n",
            "{'loss': 0.2554, 'grad_norm': 0.9333038330078125, 'learning_rate': 3.1416838871368924e-06, 'epoch': 4.62}\n",
            "{'loss': 0.246, 'grad_norm': 0.9257327318191528, 'learning_rate': 1.9281395726709397e-06, 'epoch': 4.7}\n",
            "{'loss': 0.2043, 'grad_norm': 0.7264167070388794, 'learning_rate': 1.0072802353294664e-06, 'epoch': 4.79}\n",
            "{'loss': 0.204, 'grad_norm': 1.0150697231292725, 'learning_rate': 3.8185408130445575e-07, 'epoch': 4.88}\n",
            "{'loss': 0.2175, 'grad_norm': 0.9222886562347412, 'learning_rate': 5.3727628053468204e-08, 'epoch': 4.96}\n",
            "{'train_runtime': 18475.4115, 'train_samples_per_second': 0.504, 'train_steps_per_second': 0.032, 'train_loss': 0.4137084622668405, 'epoch': 5.0}\n",
            "100% 585/585 [5:07:55<00:00, 31.58s/it]\n",
            "Training completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
        "model3 = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "model3 = PeftModel.from_pretrained(model3, \"/content/drive/MyDrive/LoRaDifferentRank/syntax_adapter\").to('cuda')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model3.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "10d90424c3e5461cb65b1714e2bc7d50",
            "c513ddd7a68b45d2a06d4d4e4212db50",
            "32b0807409334b08a3eca29efade2df2",
            "54eef423d10b47dfa7cc9aec0e313ac6",
            "59018488727044ad8c96f6509ab7b3b6",
            "461a3cebb27e46a88a0f5f41660c46f4",
            "832a25e9f7064d8bb217cd27528b859f",
            "7c63b9e8f5ed44bba0bdb4e5fa617e32",
            "e84fe182cbc54dffb86371fb07a93634",
            "a1b1a5a3254b454ba055c60de5f59e03",
            "61a1e5930b9c462ba252e4f7d7580c4f",
            "9824a99791204043844b7619ad156c39",
            "dd667787b4da4fbb92c96e6cc6b4884c",
            "1b80645936c64a9c87491b92e243d9a6",
            "8699f004ee08457c91c447ec397e3455",
            "e3e24c048f634e158588c3247f612acc",
            "8bb90f5bc7334ae482660460d018c028",
            "d9ad450120744df6bdb6bf47211abbcc",
            "c3e506d2c39a45439db0a9dca5e3758b",
            "b9857321744246aabc50a09579365889",
            "9759c0da919a4ea6901eccff26ef7e30",
            "2bfb05e3d9ea4b75ae161d3656b04d33",
            "f1c913879ae542fc85aac1bbfac7f137",
            "bd43b31e6f424f8a9d87d3613342a840",
            "1ef0e02b424949539da45389d33eb401",
            "b76b4617e4e34e98b25685d34aefdb07",
            "b9567fa3d418484d869d1a4884db441e",
            "f3c8202464714409a4eca21a1f91f270",
            "486d737529e04a3793e4abff27b0b007",
            "75553468954b4fb6806435a40ddd8c21",
            "d22593dfa5054be58f6509be912dca6f",
            "3cceea1bc25c4acbb201a2de59e63fb7",
            "7c5f6eaa708846da94e5514d3d2f9be5",
            "7072889bffbc440ca35e1f6806f14c7b",
            "361a3632c3d342acb1e81a13fb32fbe2",
            "29bcbb653eae4798bb8948cc318cc08a",
            "49f9dd11dc4b4816b9627e7029f41475",
            "3f5dec2c4b8c497e9d11d919bfa3973b",
            "2bd6a0152e584c9b831305b5b7e6a997",
            "dadb486eee0e45fcbf652729d5a68cc6",
            "e33c0b655f3546dfa62a89a5843b9075",
            "3d2b4bcc8da44c9a87f487f2bfe33633",
            "fb6d21324ab84e3183319cdefa932448",
            "2cbd8c145dec4e0ea5e1637e6ff76283",
            "6b919fbd39384377b9c2f67b0ae5f0b1",
            "9d784aebf17346a1aeb02bc504661335",
            "467e117d870f4a2bbe69de1a85d45785",
            "fd744c53423b44da9c2872325db14ea3",
            "083815f024174e7caa6c941fe3632ffc",
            "5947388f23a14aab9f59b00f8280ae50",
            "d370ec969e474e8487e1035390d723b5",
            "e10de4c45b4f435a94249e0ae03f4202",
            "f56bb5113c3e4fa89b79ae81862fa67d",
            "45edd8d0c597408b97fa28461493dfa7",
            "a4ec99ef807144a6ae1265eb372e5247"
          ]
        },
        "id": "gSyJQYh3Mlph",
        "outputId": "d62ab98d-4470-4080-98b4-c20362cd65f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10d90424c3e5461cb65b1714e2bc7d50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.69G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9824a99791204043844b7619ad156c39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1c913879ae542fc85aac1bbfac7f137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7072889bffbc440ca35e1f6806f14c7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b919fbd39384377b9c2f67b0ae5f0b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): ModulesToSaveWrapper(\n",
              "          (original_module): Embedding(32256, 2048)\n",
              "          (modules_to_save): ModuleDict(\n",
              "            (default): Embedding(32256, 2048)\n",
              "          )\n",
              "        )\n",
              "        (layers): ModuleList(\n",
              "          (0-23): 24 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=5504, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=4, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=4, out_features=5504, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=5504, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=4, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=4, out_features=5504, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=5504, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=5504, out_features=4, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=4, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=2048, out_features=32256, bias=False)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=2048, out_features=32256, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, \"Write a quick sort algorithm\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx4senXZNSi5",
        "outputId": "85f69e01-c9e9-4778-d080-4aa2219cd1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Write a quick sort algorithm\n",
            "### Response:\n",
            "function quicksort(l: array of integer): array of integer;\n",
            "begin\n",
            "  if l.Length < 2 then\n",
            "    exit(l);\n",
            "  var pivot := l[0];\n",
            "  var less := l.Where(x -> x <= pivot).ToArray;\n",
            "  var greater := l.Where(x -> x > pivot).ToArray;\n",
            "  Result := quicksort(less) + pivot + quicksort(greater);\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var a := ArrRandom(100);\n",
            "  var b := quicksort(a);\n",
            "  Println(b);\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, \"Write an algorithm to solve n-queens problem\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkSqOd9TP1JB",
        "outputId": "79c528fd-2aa4-4fdf-c71d-d1482268ad13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Write an algorithm to solve n-queens problem\n",
            "### Response:\n",
            "function Ok(x: integer; y: integer): boolean;\n",
            "begin\n",
            "  Result := All(x:1..7) and All(y:1..7) and [(xx,yy) in Queens.Where(p->Abs(p.x-xx)=Abs(p.y-yy))]\n",
            "end;\n",
            "\n",
            "procedure WP(n: integer);\n",
            "begin\n",
            "  if n<=0 then\n",
            "  begin\n",
            "    Println('Solution numbers:');\n",
            "    var x := 0;\n",
            "    Queens.OrderBy(p->p.y).Println;\n",
            "    Inc(x);\n",
            "  end\n",
            "  else\n",
            "  begin\n",
            "    for var y:=1 to 7 do\n",
            "    begin\n",
            "      if Ok(x,y) then\n",
            "      begin\n",
            "        var p := new PPoint(x,y);\n",
            "        Queens.Add(p);\n",
            "        if n=7 then\n",
            "          Println('Found one solution');\n",
            "        if n>7 then\n",
            "        begin\n",
            "          WP(n-1);\n",
            "          if n=7 then\n",
            "            Println('Found one solution');\n",
            "        end\n",
            "        else\n",
            "        begin\n",
            "          WP(n-1);\n",
            "          if n=7 then\n",
            "            Println('Found one solution');\n",
            "        end;\n",
            "        Queens.Remove(p);\n",
            "      end;\n",
            "    end;\n",
            "  end;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  WP(7);\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, \"Write a Hanoi Towers algorithm\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEKsohEgRnGj",
        "outputId": "c9a09aa4-f49f-49c8-f615-47ae4c735725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Write a Hanoi Towers algorithm\n",
            "### Response:\n",
            "procedure Towers(n: integer);\n",
            "begin\n",
            "  MoveTowers(1,3,n);\n",
            "end;\n",
            "\n",
            "procedure MoveDisk(frompeg,topeg: integer);\n",
            "begin\n",
            "  writelnFormat('Move disk: peg {0} to peg {1}',frompeg,topeg);\n",
            "end;\n",
            "\n",
            "procedure MoveTowers(frompeg,topeg,pegcount: integer);\n",
            "begin\n",
            "  if pegcount=1 then \n",
            "    MoveDisk(frompeg,topeg)\n",
            "  else \n",
            "  begin\n",
            "    MoveTowers(frompeg,pegcount-1,topeg);\n",
            "    MoveDisk(frompeg,topeg);\n",
            "    MoveTowers(pegcount-1,topeg,frompeg);\n",
            "  end;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var n: integer := 4;\n",
            "  writeln('Start moving disks.');\n",
            "  Towers(n);\n",
            "  writeln('End moving disks.');\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, '''Translate this python code to PascalABC.NET:\n",
        "def hanoi(n, source, target, auxiliary):\n",
        "    if n > 0:\n",
        "        # Move n - 1 disks from source to auxiliary, so they are out of the way\n",
        "        hanoi(n - 1, source, auxiliary, target)\n",
        "\n",
        "        # Move the nth disk from source to target\n",
        "        print('Move disk', n, 'from rod', source, 'to rod', target)\n",
        "\n",
        "        # Move the n - 1 disks that we left on auxiliary to target\n",
        "        hanoi(n - 1, auxiliary, target, source)\n",
        "\n",
        "# Test the function\n",
        "hanoi(3, 'A', 'C', 'B')\n",
        "'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kulgpFridnO",
        "outputId": "1b146a17-1d18-4cdc-b140-1b67c6515655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Translate this python code to PascalABC.NET:\n",
            "def hanoi(n, source, target, auxiliary):\n",
            "    if n > 0:\n",
            "        # Move n - 1 disks from source to auxiliary, so they are out of the way\n",
            "        hanoi(n - 1, source, auxiliary, target)\n",
            "\n",
            "        # Move the nth disk from source to target\n",
            "        print('Move disk', n, 'from rod', source, 'to rod', target)\n",
            "\n",
            "        # Move the n - 1 disks that we left on auxiliary to target\n",
            "        hanoi(n - 1, auxiliary, target, source)\n",
            "\n",
            "# Test the function\n",
            "hanoi(3, 'A', 'C', 'B')\n",
            "\n",
            "### Response:\n",
            "procedure hanoi(n: integer; source, target, auxiliary: char);\n",
            "begin\n",
            "  if n > 0 then\n",
            "  begin\n",
            "    hanoi(n - 1, source, auxiliary, target);\n",
            "    writeln('Move disk ',n,' from rod ',source,' to rod ',target);\n",
            "    hanoi(n - 1, auxiliary, target, source);\n",
            "  end;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  hanoi(3, 'A', 'C', 'B');\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, '''Translate this python code to PascalABC.NET with minimal changes to the original solution:\n",
        "  def solve_n_queens(n):\n",
        "    def is_attack(i, j):\n",
        "        # Check for any queen in the same row\n",
        "        for k in range(0, n):\n",
        "            if board[i][k] == 1:\n",
        "                return True\n",
        "\n",
        "        # Check for any queen in the same column\n",
        "        for k in range(0, n):\n",
        "            if board[k][j] == 1:\n",
        "                return True\n",
        "\n",
        "        # Check for any queen in the same diagonal\n",
        "        for k in range(0, n):\n",
        "            for l in range(0, n):\n",
        "                if (k + l == i + j) or (k - l == i - j):\n",
        "                    if board[k][l] == 1:\n",
        "                        return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def solve_n_queens_util(n, i):\n",
        "        # base case\n",
        "        if i == n:\n",
        "            return True\n",
        "\n",
        "        for j in range(0, n):\n",
        "            if not is_attack(i, j):\n",
        "                # place queen at board[i][j]\n",
        "                board[i][j] = 1\n",
        "\n",
        "                # recur to place rest of the queens\n",
        "                if solve_n_queens_util(n, i + 1) == True:\n",
        "                    return True\n",
        "\n",
        "                # If placing queen in board[i][j] doesn't lead to a solution, then\n",
        "                # remove queen from board[i][j]\n",
        "                board[i][j] = 0\n",
        "\n",
        "        return False\n",
        "\n",
        "    board = [[0]*n for _ in range(n)]\n",
        "\n",
        "    if solve_n_queens_util(n, 0) == False:\n",
        "        print(\"Solution does not exist\")\n",
        "        return False\n",
        "\n",
        "    print_board(board, n)\n",
        "    return True'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gogot4ZJihjK",
        "outputId": "6d771aa8-4933-4d08-afdd-568074d23518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Translate this python code to PascalABC.NET with minimal changes to the original solution:\n",
            "  def solve_n_queens(n):\n",
            "    def is_attack(i, j):\n",
            "        # Check for any queen in the same row\n",
            "        for k in range(0, n):\n",
            "            if board[i][k] == 1:\n",
            "                return True\n",
            "\n",
            "        # Check for any queen in the same column\n",
            "        for k in range(0, n):\n",
            "            if board[k][j] == 1:\n",
            "                return True\n",
            "\n",
            "        # Check for any queen in the same diagonal\n",
            "        for k in range(0, n):\n",
            "            for l in range(0, n):\n",
            "                if (k + l == i + j) or (k - l == i - j):\n",
            "                    if board[k][l] == 1:\n",
            "                        return True\n",
            "\n",
            "        return False\n",
            "\n",
            "    def solve_n_queens_util(n, i):\n",
            "        # base case\n",
            "        if i == n:\n",
            "            return True\n",
            "\n",
            "        for j in range(0, n):\n",
            "            if not is_attack(i, j):\n",
            "                # place queen at board[i][j]\n",
            "                board[i][j] = 1\n",
            "\n",
            "                # recur to place rest of the queens\n",
            "                if solve_n_queens_util(n, i + 1) == True:\n",
            "                    return True\n",
            "\n",
            "                # If placing queen in board[i][j] doesn't lead to a solution, then\n",
            "                # remove queen from board[i][j]\n",
            "                board[i][j] = 0\n",
            "\n",
            "        return False\n",
            "\n",
            "    board = [[0]*n for _ in range(n)]\n",
            "\n",
            "    if solve_n_queens_util(n, 0) == False:\n",
            "        print(\"Solution does not exist\")\n",
            "        return False\n",
            "\n",
            "    print_board(board, n)\n",
            "    return True\n",
            "### Response:\n",
            "var \n",
            "  board: array [0..99,0..99] of integer;\n",
            "  n: integer;\n",
            "\n",
            "function print_board(b: array [0..99,0..99] of integer; n: integer);\n",
            "begin\n",
            "  for var i:=0 to n-1 do\n",
            "  begin\n",
            "    for var j:=0 to n-1 do\n",
            "      write(b[i,j]);\n",
            "    writeln;  \n",
            "  end;  \n",
            "end;\n",
            "\n",
            "function is_attack(i,j: integer): boolean;\n",
            "begin\n",
            "  Result := False;\n",
            "  for var k:=0 to n-1 do\n",
            "    if board[i,k] = 1 or board[k,j] = 1 then\n",
            "    begin\n",
            "      Result := True;\n",
            "      exit;\n",
            "    end;\n",
            "  for var k:=0 to n-1 do\n",
            "    for var l:=0 to n-1 do\n",
            "      if (k+l=i+j) or (k-l=i-j) then\n",
            "        if board[k,l] = 1 then\n",
            "        begin\n",
            "          Result := True;\n",
            "          exit;\n",
            "        end;\n",
            "end;\n",
            "\n",
            "function solve_n_queens_util(n,i: integer): boolean;\n",
            "begin\n",
            "  Result := False;\n",
            "  for j:=0 to n-1 do\n",
            "    if not is_attack(i,j) then\n",
            "    begin\n",
            "      board[i,j] := 1;\n",
            "      if i = n-1 then\n",
            "        exit(True);\n",
            "      if solve_n_queens_util(n,i+1) then\n",
            "        exit(True);\n",
            "      board[i,j] := 0;\n",
            "    end;\n",
            "end;\n",
            "\n",
            "function solve_n_queens(n: integer): boolean;\n",
            "begin\n",
            "  Result := False;\n",
            "  if solve_n_queens_util(n,0) then\n",
            "    exit(True);\n",
            "end;\n",
            "\n",
            "begin\n",
            "  n := 10;\n",
            "  solve_n_queens(n);\n",
            "  print_board(board,n);\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, 'Write a function which checks whether string is a palindrom or not'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsjr8mNelNTq",
        "outputId": "c5496ccb-b718-4b98-db70-f5380ec3640b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Write a function which checks whether string is a palindrom or not\n",
            "### Response:\n",
            "function IsPalindrome(s: string): boolean;\n",
            "begin\n",
            "  Result := s = ReverseString(s);\n",
            "end;\n",
            "\n",
            "begin\n",
            "  IsPalindrome('madam').Println;\n",
            "  IsPalindrome('12321').Println;\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, 'Write a function which checks whether string is a palindrom or not. Do not use standard PascalABC.NET functions.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAsj5yZK9fMO",
        "outputId": "289867c2-a1fb-4956-d8ae-658954c78011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "Write a function which checks whether string is a palindrom or not. Do not use standard PascalABC.NET functions.\n",
            "### Response:\n",
            "function Is_Palindrome(s: string): boolean;\n",
            "begin\n",
            "  var L := s.Length;\n",
            "  var k := 0;\n",
            "  while k < L div 2 do\n",
            "  begin\n",
            "    if s[k] <> s[L-k-1] then\n",
            "      exit(False);\n",
            "    k += 1;\n",
            "  end;\n",
            "  Result := True;\n",
            "end;\n",
            "\n",
            "begin\n",
            "  var s := 'madam';\n",
            "  Is_Palindrome(s).Println;\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, '''\n",
        "Implement depth-first search for a graph represented as an adjacency list. The code should:\n",
        "\n",
        "- Take a starting node and a graph structure as input\n",
        "- Return the order in which nodes are visited\n",
        "- Handle cycles using a visited set/map\n",
        "- Work for both connected and disconnected graphs\n",
        "\n",
        "Include both recursive and iterative implementations using a stack.'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jRGPe_U-kWr",
        "outputId": "8bcd9eff-4321-46ba-f52f-c46f20968b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Implement depth-first search for a graph represented as an adjacency list. The code should:\n",
            "\n",
            "- Take a starting node and a graph structure as input\n",
            "- Return the order in which nodes are visited\n",
            "- Handle cycles using a visited set/map\n",
            "- Work for both connected and disconnected graphs\n",
            "\n",
            "Include both recursive and iterative implementations using a stack.\n",
            "### Response:\n",
            "// Depth-first search for a graph represented as an adjacency list\n",
            "procedure DFS(start: integer; graph: array of array of integer; visited: array of boolean);\n",
            "// recursive implementation\n",
            "begin\n",
            "  Print(start);\n",
            "  visited[start] := True;\n",
            "  foreach var x in graph[start] do\n",
            "    if not visited[x] then\n",
            "      DFS(x, graph, visited);\n",
            "end;\n",
            "\n",
            "procedure DFS(start: integer; graph: array of array of integer);\n",
            "// iterative implementation\n",
            "// uses stack\n",
            "var\n",
            "  stack: Stack<integer>;\n",
            "  visited: array of boolean;\n",
            "\n",
            "begin\n",
            "  Fill(visited, False);\n",
            "  stack := new Stack<integer>;\n",
            "\n",
            "  Print(start);\n",
            "  visited[start] := True;\n",
            "  stack.Push(start);\n",
            "\n",
            "  while not stack.IsEmpty do\n",
            "  begin\n",
            "    var x := stack.Pop;\n",
            "    foreach var n in graph[x] do\n",
            "      if not visited[n] then\n",
            "      begin\n",
            "        Print(n);\n",
            "        visited[n] := True;\n",
            "        stack.Push(n);\n",
            "      end;\n",
            "  end;\n",
            "end;\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, '''\n",
        "Write a comprehensive binary search implementation that includes:\n",
        "\n",
        "1. Standard binary search to find if a target exists\n",
        "2. Find the first occurrence of a target in a sorted array with duplicates\n",
        "3. Find the insertion position for a target in a sorted array\n",
        "4. Handle edge cases like empty arrays and targets not found\n",
        "\n",
        "Each variation should be implemented as a separate function.'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Heyq9ZlBGuw",
        "outputId": "a29b065f-4a35-4c03-d388-f26e99e6e47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Write a comprehensive binary search implementation that includes:\n",
            "\n",
            "1. Standard binary search to find if a target exists\n",
            "2. Find the first occurrence of a target in a sorted array with duplicates\n",
            "3. Find the insertion position for a target in a sorted array\n",
            "4. Handle edge cases like empty arrays and targets not found\n",
            "\n",
            "Each variation should be implemented as a separate function.\n",
            "### Response:\n",
            "function BinarySearch(a: array of integer; x: integer): boolean;\n",
            "begin\n",
            "  var lo := 0;\n",
            "  var hi := a.Length - 1;\n",
            "  while lo <= hi do\n",
            "  begin\n",
            "    var mi := (lo + hi) div 2;\n",
            "    if a[mi] < x then lo := mi + 1\n",
            "    else if a[mi] > x then hi := mi - 1\n",
            "    else exit True;\n",
            "  end;\n",
            "  Result := False;\n",
            "end;\n",
            "\n",
            "function FirstIndex(a: array of integer; x: integer): integer;\n",
            "begin\n",
            "  var lo := 0;\n",
            "  var hi := a.Length - 1;\n",
            "  while lo <= hi do\n",
            "  begin\n",
            "    var mi := (lo + hi) div 2;\n",
            "    if a[mi] < x then lo := mi + 1\n",
            "    else if a[mi] > x then hi := mi - 1\n",
            "    else exit mi;\n",
            "  end;\n",
            "  Result := -1;\n",
            "end;\n",
            "\n",
            "function FindInsertionPoint(a: array of integer; x: integer): integer;\n",
            "begin\n",
            "  var lo := 0;\n",
            "  var hi := a.Length - 1;\n",
            "  while lo <= hi do\n",
            "  begin\n",
            "    var mi := (lo + hi) div 2;\n",
            "    if a[mi] < x then lo := mi + 1\n",
            "    else if a[mi] > x then hi := mi - 1\n",
            "    else exit mi;\n",
            "  end;\n",
            "  Result := lo;\n",
            "end;\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model(model3, '''\n",
        "Write a program to find all prime numbers up to a given number N using the Sieve of Eratosthenes algorithm. Do not declare variables outside of begin-end block.'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_2Is2t2B2XH",
        "outputId": "003d1c2d-b855-4387-c825-c2192e972824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a PascalABC.NET coding assistant. Follow these rules:\n",
            "1. Write only PascalABC.NET code\n",
            "2. Provide complete programs when possible\n",
            "3. Use modern PascalABC.NET features\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Write a program to find all prime numbers up to a given number N using the Sieve of Eratosthenes algorithm. Do not declare variables outside of begin-end block.\n",
            "### Response:\n",
            "begin\n",
            "  var N:=ReadInt('Enter N: ');\n",
            "  var a:=ArrGen(N+1,i->True);\n",
            "  a[0:2] := (0,0);\n",
            "  for var i:=2 to Round(Sqrt(N)) do\n",
            "    if a[i] then\n",
            "      for var j:=i*i to N step i do\n",
            "        a[j] := False;\n",
            "  Println('Prime numbers: ',Where(a));\n",
            "end.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "        \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
        "        model_max_length=1024,\n",
        "        padding_side=\"right\",\n",
        "        use_fast=True,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "\n",
        "with open('/content/train_data.json', 'r', encoding='utf-8') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "text_lengths = []\n",
        "for item in train_data:\n",
        "    full_text = item['instruction'] + \" \" + item['output']\n",
        "    tokens_length = len(tokenizer.encode(full_text))\n",
        "\n",
        "    if tokens_length > 1024:\n",
        "      print(item['instruction'], tokens_length)\n",
        "    text_lengths.append(tokens_length)\n",
        "\n",
        "# Статистика\n",
        "print(f\"Всего примеров: {len(text_lengths)}\")\n",
        "print(f\"Мин. длина: {np.min(text_lengths)}\")\n",
        "print(f\"Макс. длина: {np.max(text_lengths)}\")\n",
        "print(f\"Средняя длина: {np.mean(text_lengths):.1f}\")\n",
        "print(f\"Медиана: {np.median(text_lengths)}\")\n",
        "print(f\"95-й перцентиль: {np.percentile(text_lengths, 95)}\")\n",
        "print(f\"99-й перцентиль: {np.percentile(text_lengths, 99)}\")"
      ],
      "metadata": {
        "id": "abnHwvCiIr2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c9c129-05a6-4c0d-e236-2583eb14bf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implement the classic 15 puzzle game in PascalABC.NET using GraphABC and ABCObjects with tile movement, shuffling, and win condition detection 1633\n",
            "Create interactive standard colors palette with ABCObjects using reflection 1365\n",
            "Create interactive standard colors palette with WPFObjects using reflection 1385\n",
            "Implement Tower of Hanoi algorithm with graphical visualization in GraphABC 1150\n",
            "Create a shooting game in PascalABC.NET using ABCObjects where the player controls a rectangle at the bottom and shoots bullets at colored enemy rectangles. Implement keyboard controls, collision detection, scoring system, and game states. 1796\n",
            "Implement Conway's Game of Life on a toroidal grid in PascalABC.NET using GraphWPF with optimization through uniform grid hashing. The program should handle cell updates efficiently and display generation information. 2621\n",
            "Implement complex fish ecosystem simulation with predator-prey behavior using GraphABC in PascalABC.NET 3676\n",
            "Implement word game with letter boards and word validation in PascalABC.NET using GraphABC 2264\n",
            "Create an enhanced ray casting function in PascalABC.NET with colored lighting, emission effects, gradient sky, and light attenuation. 1070\n",
            "Implement main ray casting function with lighting and materials in PascalABC.NET 1058\n",
            "Create a simple shooter game with player, monsters and bullets using WPFObjects in PascalABC.NET 1061\n",
            "Create programs that demonstrate different text alignment options in GraphWPF for both rectangle areas and point coordinates. 1053\n",
            "Write a PascalABC.NET class for Chebyshev polynomial approximation of tabular function using least squares method 1150\n",
            "Write a PascalABC.NET class for LU decomposition of real matrix for solving linear equation systems 1147\n",
            "Write a PascalABC.NET class for finding all roots of polynomial with real coefficients using Newton-Raphson method 1271\n",
            "Write a PascalABC.NET class for adaptive quadrature numerical integration using QUANC8 algorithm 1595\n",
            "Write a PascalABC.NET class for Runge-Kutta-Fehlberg 4th-5th order method for solving ordinary differential equations 2802\n",
            "Write a PascalABC.NET class for cubic spline interpolation of tabular function 1542\n",
            "Implement structured object to string conversion with recursive formatting 1243\n",
            "Всего примеров: 1862\n",
            "Мин. длина: 16\n",
            "Макс. длина: 3676\n",
            "Средняя длина: 153.5\n",
            "Медиана: 87.0\n",
            "95-й перцентиль: 507.84999999999945\n",
            "99-й перцентиль: 1025.5499999999943\n"
          ]
        }
      ]
    }
  ]
}